{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPvmjm340azr",
        "outputId": "87f15747-57c1-48c6-a4cc-9da9b7afedd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxduMSKe0Fv-",
        "outputId": "e3aae5ea-0cdb-4b3a-d6ef-5a6e4841b210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "# from operator import itemgetter\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXmg02oT8Eqj",
        "outputId": "7e14ecbf-79bd-4189-f40a-fb0d0d7813a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sample_text = \"This is a test. Let's see if this works.\"\n",
        "print(sent_tokenize(sample_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h8RFXlI3TsG",
        "outputId": "ae4d7056-47fa-4cd5-9dc9-06b16f3243e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is a test.', \"Let's see if this works.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"zynicide/wine-reviews\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# List files in the dataset directory\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXTRlr5e0m5M",
        "outputId": "1c9950e2-f2d9-4758-c999-45ddfde740f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/zynicide/wine-reviews/versions/4\n",
            "['winemag-data-130k-v2.json', 'winemag-data-130k-v2.csv', 'winemag-data_first150k.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww-jJlhk0Fv_"
      },
      "source": [
        "First, import the wine dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the CSV file\n",
        "csv_path = os.path.join(path, \"winemag-data-130k-v2.csv\")\n",
        "\n",
        "# Load the CSV file\n",
        "df_wine = pd.read_csv(csv_path)\n",
        "\n",
        "# Preview the data\n",
        "print(df_wine.head())\n",
        "print(df_wine.columns)\n",
        "print(df_wine.info())\n",
        "print(df_wine.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vTefZRP0oea",
        "outputId": "d7f369d4-ff7a-4c43-edac-40d79fdc6e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0   country                                        description  \\\n",
            "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
            "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
            "2           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
            "3           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
            "4           4        US  Much like the regular bottling from 2012, this...   \n",
            "\n",
            "                          designation  points  price           province  \\\n",
            "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
            "1                            Avidagos      87   15.0              Douro   \n",
            "2                                 NaN      87   14.0             Oregon   \n",
            "3                Reserve Late Harvest      87   13.0           Michigan   \n",
            "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
            "\n",
            "              region_1           region_2         taster_name  \\\n",
            "0                 Etna                NaN       Kerin O’Keefe   \n",
            "1                  NaN                NaN          Roger Voss   \n",
            "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
            "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
            "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
            "\n",
            "  taster_twitter_handle                                              title  \\\n",
            "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
            "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
            "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
            "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
            "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
            "\n",
            "          variety               winery  \n",
            "0     White Blend              Nicosia  \n",
            "1  Portuguese Red  Quinta dos Avidagos  \n",
            "2      Pinot Gris            Rainstorm  \n",
            "3        Riesling           St. Julian  \n",
            "4      Pinot Noir         Sweet Cheeks  \n",
            "Index(['Unnamed: 0', 'country', 'description', 'designation', 'points',\n",
            "       'price', 'province', 'region_1', 'region_2', 'taster_name',\n",
            "       'taster_twitter_handle', 'title', 'variety', 'winery'],\n",
            "      dtype='object')\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 129971 entries, 0 to 129970\n",
            "Data columns (total 14 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   Unnamed: 0             129971 non-null  int64  \n",
            " 1   country                129908 non-null  object \n",
            " 2   description            129971 non-null  object \n",
            " 3   designation            92506 non-null   object \n",
            " 4   points                 129971 non-null  int64  \n",
            " 5   price                  120975 non-null  float64\n",
            " 6   province               129908 non-null  object \n",
            " 7   region_1               108724 non-null  object \n",
            " 8   region_2               50511 non-null   object \n",
            " 9   taster_name            103727 non-null  object \n",
            " 10  taster_twitter_handle  98758 non-null   object \n",
            " 11  title                  129971 non-null  object \n",
            " 12  variety                129970 non-null  object \n",
            " 13  winery                 129971 non-null  object \n",
            "dtypes: float64(1), int64(2), object(11)\n",
            "memory usage: 13.9+ MB\n",
            "None\n",
            "Unnamed: 0                   0\n",
            "country                     63\n",
            "description                  0\n",
            "designation              37465\n",
            "points                       0\n",
            "price                     8996\n",
            "province                    63\n",
            "region_1                 21247\n",
            "region_2                 79460\n",
            "taster_name              26244\n",
            "taster_twitter_handle    31213\n",
            "title                        0\n",
            "variety                      1\n",
            "winery                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "source": [
        "Then, the food dataset."
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "jh1CNip40FwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path2 = kagglehub.dataset_download(\"snap/amazon-fine-food-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path2)"
      ],
      "metadata": {
        "id": "9XM4aZCF1P_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the CSV file\n",
        "csv_path2 = os.path.join(path2, \"Reviews.csv\")\n",
        "\n",
        "# Load the CSV file\n",
        "df_food = pd.read_csv(csv_path2)\n",
        "\n",
        "# Preview the data\n",
        "print(df_food.head())\n",
        "print(df_food.columns)\n",
        "print(df_food.info())\n",
        "print(df_food.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqpo7Fqb0ySf",
        "outputId": "5ce06997-f087-4c79-a972-31341cea2b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id   ProductId          UserId                      ProfileName  \\\n",
            "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
            "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
            "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
            "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
            "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
            "0                     1                       1      5  1303862400   \n",
            "1                     0                       0      1  1346976000   \n",
            "2                     1                       1      4  1219017600   \n",
            "3                     3                       3      2  1307923200   \n",
            "4                     0                       0      5  1350777600   \n",
            "\n",
            "                 Summary                                               Text  \n",
            "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
            "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
            "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
            "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
            "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
            "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
            "      dtype='object')\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568428 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n",
            "None\n",
            "Id                         0\n",
            "ProductId                  0\n",
            "UserId                     0\n",
            "ProfileName               26\n",
            "HelpfulnessNumerator       0\n",
            "HelpfulnessDenominator     0\n",
            "Score                      0\n",
            "Time                       0\n",
            "Summary                   27\n",
            "Text                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUpCe0rl0FwB"
      },
      "source": [
        "### 1. Training our Word Embeddings\n",
        "\n",
        "First, we need to train a Word2Vec model on all the words in our corpus. We will process our wine and food terms separately - some of the wine terms will be standardized to account for commonalities in the colorful language of the world of wine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P6n7o9k0FwB"
      },
      "outputs": [],
      "source": [
        "wine_reviews_list = list(df_wine['description'])\n",
        "food_reviews_list = list(df_food['Text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBjtKrxc0FwC"
      },
      "source": [
        "To begin, we need to tokenize the terms in our corpus (wine and food)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bqd3Bl60FwC",
        "outputId": "509b905f-e996-4aee-e052-aa5e64302d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aromas include tropical fruit, broom, brimstone and dried herb.', \"The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\"]\n",
            "['I have bought several of the Vitality canned dog food products and have found them all to be of good quality.', 'The product looks more like a stew than a processed meat and it smells better.']\n"
          ]
        }
      ],
      "source": [
        "full_wine_reviews_list = [str(r) for r in wine_reviews_list]\n",
        "full_wine_corpus = ' '.join(full_wine_reviews_list)\n",
        "wine_sentences_tokenized = sent_tokenize(full_wine_corpus)\n",
        "\n",
        "full_food_reviews_list = [str(r) for r in food_reviews_list]\n",
        "full_food_corpus = ' '.join(full_food_reviews_list)\n",
        "food_sentences_tokenized = sent_tokenize(full_food_corpus)\n",
        "\n",
        "print(wine_sentences_tokenized[:2])\n",
        "print(food_sentences_tokenized[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXSP9DQo0FwC"
      },
      "source": [
        "Next, the text in each sentence is normalized (tokenize, remove punctuation and remove stopwords)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDS8Zq5l0FwC"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "punctuation_table = str.maketrans({key: None for key in string.punctuation})\n",
        "sno = SnowballStemmer('english')\n",
        "\n",
        "def normalize_text(raw_text):\n",
        "    try:\n",
        "        word_list = word_tokenize(raw_text)\n",
        "        normalized_sentence = []\n",
        "        for w in word_list:\n",
        "            try:\n",
        "                w = str(w)\n",
        "                lower_case_word = str.lower(w)\n",
        "                stemmed_word = sno.stem(lower_case_word)\n",
        "                no_punctuation = stemmed_word.translate(punctuation_table)\n",
        "                if len(no_punctuation) > 1 and no_punctuation not in stop_words:\n",
        "                    normalized_sentence.append(no_punctuation)\n",
        "            except:\n",
        "                continue\n",
        "        return normalized_sentence\n",
        "    except:\n",
        "        return ''\n",
        "\n",
        "normalized_wine_sentences = []\n",
        "for s in wine_sentences_tokenized:\n",
        "    normalized_text = normalize_text(s)\n",
        "    normalized_wine_sentences.append(normalized_text)\n",
        "\n",
        "normalized_food_sentences = []\n",
        "for s in food_sentences_tokenized:\n",
        "    normalized_text = normalize_text(s)\n",
        "    normalized_food_sentences.append(normalized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmzXUI5W0FwD"
      },
      "source": [
        "Not all of the terms we are interested in are single words. Some of the terms are phrases, consisting of two (or more!) words. An example of this might be 'high tannin'. We can use gensim's Phrases feature to extract all the most relevant bi- and tri-grams from our corpus.\n",
        "\n",
        "We will train a separate trigram model for wine and for food."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIw0hg_t0FwD"
      },
      "outputs": [],
      "source": [
        "# first, take care of the wine trigrams\n",
        "# wine_bigram_model = Phrases(normalized_wine_sentences, min_count=100)\n",
        "# wine_bigrams = [wine_bigram_model[line] for line in normalized_wine_sentences]\n",
        "# wine_trigram_model = Phrases(wine_bigrams, min_count=50)\n",
        "# phrased_wine_sentences = [wine_trigram_model[line] for line in wine_bigrams]\n",
        "# wine_trigram_model.save('wine_trigrams.pkl')\n",
        "\n",
        "### now, do the same for food\n",
        "food_bigram_model = Phrases(normalized_food_sentences, min_count=100)\n",
        "food_bigrams = [food_bigram_model[sent] for sent in normalized_food_sentences]\n",
        "food_trigram_model = Phrases(food_bigrams, min_count=50)\n",
        "phrased_food_sentences = [food_trigram_model[sent] for sent in food_bigrams]\n",
        "food_trigram_model.save('food_trigrams.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL2O7n2u0FwD"
      },
      "source": [
        "If the trigram model has already been trained, simply retrieve it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rk2Ti3g0FwD"
      },
      "outputs": [],
      "source": [
        "wine_trigram_model = Phraser.load('wine_trigrams.pkl')\n",
        "food_trigram_model = Phraser.load('food_trigrams.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLuyBy_O0FwD"
      },
      "source": [
        "Now for the most important part: leveraging existing wine theory, the work of others like Bernard Chen, wine descriptor mappings and the UC Davis wine wheel, the top 5000 most frequent wine terms were reviewed to (i) determine whether they are a descriptor that can be derived by blind tasting, and (ii) whether they are informative (judgments like 'tasty' and 'great' are not considered to be informative). The roughly 1000 descriptors that remain were then mapped onto a normalized descriptor, a category and a class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcX6eKcA0FwD"
      },
      "outputs": [],
      "source": [
        "descriptor_mapping = pd.read_csv('descriptor_mapping.csv', encoding='latin1').set_index('raw descriptor')\n",
        "\n",
        "def return_mapped_descriptor(word, mapping):\n",
        "    if word in list(mapping.index):\n",
        "        normalized_word = mapping.at[word, 'level_3']\n",
        "        return normalized_word\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "normalized_wine_sentences = []\n",
        "for sent in phrased_wine_sentences:\n",
        "    normalized_wine_sentence = []\n",
        "    for word in sent:\n",
        "        normalized_word = return_mapped_descriptor(word, descriptor_mapping)\n",
        "        normalized_wine_sentence.append(str(normalized_word))\n",
        "    normalized_wine_sentences.append(normalized_wine_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9IcR_Nu0FwD"
      },
      "source": [
        "We will go through the same process for food, but without normalizing the nonaroma descriptors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU31n30z0FwD"
      },
      "outputs": [],
      "source": [
        "aroma_descriptor_mapping = descriptor_mapping.loc[descriptor_mapping['type'] == 'aroma']\n",
        "normalized_food_sentences = []\n",
        "for sent in phrased_food_sentences:\n",
        "    normalized_food_sentence = []\n",
        "    for word in sent:\n",
        "        normalized_word = return_mapped_descriptor(word, aroma_descriptor_mapping)\n",
        "        normalized_food_sentence.append(str(normalized_word))\n",
        "    normalized_food_sentences.append(normalized_food_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiSf78hZ0FwD"
      },
      "source": [
        "Now, let's combine the wine dataset with our food dataset so we can train our embeddings. We want to make sure that the food and wine embeddings are calculated in the same feature space so that we can compute similarity vectors later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55C8f3mF0FwD"
      },
      "outputs": [],
      "source": [
        "normalized_sentences = normalized_wine_sentences + normalized_food_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7MbSqLn0FwE"
      },
      "source": [
        "We are ready to train our Word2Vec model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pRn-YNZ_0FwE",
        "outputId": "c23c8ee9-04c3-478d-bae7-bb5ee67f3d01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec<vocab=36695, vector_size=300, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "wine_word2vec_model = Word2Vec(normalized_sentences, size=300, min_count=8, iter=15)\n",
        "print(wine_word2vec_model)\n",
        "\n",
        "wine_word2vec_model.save('food_word2vec_model.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RN8DbtRB0FwE"
      },
      "outputs": [],
      "source": [
        "# if the word2vec model has already been trained, simply load it\n",
        "wine_word2vec_model = Word2Vec.load(\"food_word2vec_model.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zezDOE8j0FwE"
      },
      "source": [
        "### 2. Preprocessing our Wine Dataset\n",
        "\n",
        "We can now turn our attention to our wine dataset. Descriptions for a single wine are unlikely to contain sufficient information about all the nonaromas and aromas to yield consistent and reliable pairing recommendations. As such, we will produce recommendations at the grape variety & subregion level.\n",
        "\n",
        "First, let's normalize the names of the grape varieties in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the unique values in the 'variety' column\n",
        "unique_varieties = df_wine['variety'].unique()\n",
        "print(f\"Unique grape varieties ({len(unique_varieties)} total):\")\n",
        "print(unique_varieties)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxV2Pdf6t5Af",
        "outputId": "2ebc964a-7e66-4f39-d56b-0bab9d9da64d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique grape varieties (708 total):\n",
            "['White Blend' 'Portuguese Red' 'Pinot Gris' 'Riesling' 'Pinot Noir'\n",
            " 'Tempranillo-Merlot' 'Frappato' 'Gewürztraminer' 'Cabernet Sauvignon'\n",
            " 'Nerello Mascalese' 'Chardonnay' 'Malbec' 'Tempranillo Blend' 'Meritage'\n",
            " 'Red Blend' 'Merlot' \"Nero d'Avola\" 'Chenin Blanc' 'Gamay'\n",
            " 'Sauvignon Blanc' 'Viognier-Chardonnay' 'Primitivo' 'Catarratto'\n",
            " 'Inzolia' 'Petit Verdot' 'Monica' 'Bordeaux-style White Blend' 'Grillo'\n",
            " 'Sangiovese' 'Cabernet Franc' 'Champagne Blend'\n",
            " 'Bordeaux-style Red Blend' 'Aglianico' 'Petite Sirah' 'Touriga Nacional'\n",
            " 'Carmenère' 'Albariño' 'Petit Manseng' 'Rosé' 'Zinfandel' 'Vernaccia'\n",
            " 'Rosato' 'Grüner Veltliner' 'Viognier' 'Vermentino' 'Grenache Blanc'\n",
            " 'Syrah' 'Nebbiolo' 'Shiraz-Cabernet Sauvignon' 'Pinot Blanc'\n",
            " 'Alsace white blend' 'Barbera' 'Rhône-style Red Blend' 'Portuguese White'\n",
            " 'Graciano' 'Tannat-Cabernet' 'Sauvignon' 'Sangiovese Grosso' 'Torrontés'\n",
            " 'Prugnolo Gentile' 'G-S-M' 'Verdejo' 'Fumé Blanc' 'Furmint'\n",
            " 'Pinot Bianco' 'Bonarda' 'Shiraz' 'Montepulciano' 'Moscato' 'Grenache'\n",
            " 'Ugni Blanc-Colombard' 'Syrah-Viognier' 'Blaufränkisch' 'Friulano'\n",
            " 'Assyrtico' 'Carignan-Grenache' 'Sagrantino' 'Savagnin'\n",
            " 'Cabernet Sauvignon-Syrah' 'Prosecco' 'Vignoles' 'Sparkling Blend'\n",
            " 'Muscat' 'Muscadelle' 'Shiraz-Viognier' 'Garganega' 'Pinot Grigio'\n",
            " 'Tempranillo' 'Zierfandler' 'Cortese' 'Mencía' 'Zweigelt' 'Melon'\n",
            " 'Rhône-style White Blend' 'Vidal' 'Cannonau' 'Verdelho' 'Marsanne'\n",
            " 'Scheurebe' 'Kerner' 'Syrah-Grenache' 'Dolcetto' 'Vilana' 'Glera' 'Viura'\n",
            " 'Garnacha Tintorera' 'Pinot Nero' 'Roter Veltliner' 'Pinotage' 'Sémillon'\n",
            " 'Pinot Noir-Gamay' 'Antão Vaz' 'Cabernet Sauvignon-Carmenère'\n",
            " 'Verdejo-Viura' 'Verduzzo' 'Verdicchio' 'Silvaner' 'Colombard'\n",
            " 'Carricante' 'Sylvaner' 'Fiano' 'Früburgunder' 'Sousão' 'Roussanne'\n",
            " 'Avesso' 'Cinsault' 'Chinuri' 'Tinta Miúda'\n",
            " 'Muscat Blanc à Petits Grains' 'Portuguese Sparkling' 'Monastrell'\n",
            " 'Xarel-lo' 'Greco' 'Trebbiano' 'Corvina, Rondinella, Molinara' 'Port'\n",
            " 'Chenin Blanc-Chardonnay' 'Insolia' 'Merlot-Malbec' 'Ribolla Gialla'\n",
            " 'Cabernet Sauvignon-Merlot' 'Duras' 'Weissburgunder' 'Roditis' 'Traminer'\n",
            " 'Papaskarasi' 'Tannat-Syrah' 'Marsanne-Roussanne' 'Charbono'\n",
            " 'Merlot-Argaman' 'Prié Blanc' 'Sherry' 'Provence red blend' 'Tannat'\n",
            " 'Zibibbo' 'Falanghina' 'Garnacha' 'Negroamaro' 'Mourvèdre'\n",
            " 'Syrah-Cabernet' 'Müller-Thurgau' 'Pinot Meunier'\n",
            " 'Cabernet Sauvignon-Sangiovese' 'Austrian Red Blend' 'Teroldego'\n",
            " 'Pansa Blanca' 'Muskat Ottonel' 'Sauvignon Blanc-Semillon' 'Claret'\n",
            " 'Semillon-Sauvignon Blanc' 'Bical' 'Moscatel' 'Rosado' 'Viura-Chardonnay'\n",
            " 'Baga' 'Malvasia Bianca' 'Gelber Muskateller' 'Malbec-Merlot'\n",
            " 'Monastrell-Syrah' 'Malbec-Tannat' 'Malbec-Cabernet Franc' 'Turbiana'\n",
            " 'Refosco' 'Alvarinho' 'Manzoni' 'Aragonês' 'Agiorgitiko' 'Malagousia'\n",
            " 'Assyrtiko' 'Ruché' 'Welschriesling' 'Tinta de Toro' 'Cabernet Moravia'\n",
            " 'Rieslaner' 'Traminette' 'Chambourcin' 'Nero di Troia'\n",
            " 'Lambrusco di Sorbara' 'Cesanese' 'Feteasca Neagra' 'Lagrein'\n",
            " 'Tinta Fina' 'St. Laurent' 'Marsanne-Viognier'\n",
            " 'Cabernet Sauvignon-Shiraz' 'Syrah-Cabernet Sauvignon'\n",
            " 'Gewürztraminer-Riesling' 'Pugnitello' 'Cerceal' 'Touriga Nacional Blend'\n",
            " 'Austrian white blend' 'Tocai' 'Tinta Roriz' 'Chardonnay-Viognier'\n",
            " 'Fernão Pires' 'Cabernet Franc-Cabernet Sauvignon' 'Grenache-Syrah'\n",
            " 'Seyval Blanc' 'Muscat Canelli' 'Cabernet Merlot'\n",
            " 'Tempranillo-Cabernet Sauvignon' 'Arinto' 'Aragonez'\n",
            " 'Merlot-Cabernet Franc' 'Syrah-Petite Sirah' 'Cabernet Blend' 'Maturana'\n",
            " 'Pecorino' 'Rotgipfler' 'Kinali Yapincak' 'Cabernet Franc-Carmenère'\n",
            " 'Magliocco' 'Gamay Noir' 'Sauvignon Gris' 'Spätburgunder' 'Picpoul'\n",
            " 'Vidal Blanc' 'Albanello' 'White Port' 'Arneis' 'Malvasia' 'Plavac Mali'\n",
            " 'Lemberger' 'Saperavi' 'Altesse' 'Blanc du Bois' 'Provence white blend'\n",
            " 'Nosiola' 'Dornfelder' 'Roussanne-Viognier' 'Ojaleshi' 'Godello'\n",
            " 'Mondeuse' 'Perricone' 'Pedro Ximénez' 'Auxerrois' 'Syrah-Merlot'\n",
            " 'Albana' 'Muskat' 'Lambrusco' 'Cabernet Sauvignon-Malbec' 'Tinto Fino'\n",
            " 'Malbec-Cabernet Sauvignon' 'Moschofilero' 'Grechetto' 'Encruzado'\n",
            " 'Carignano' 'Cabernet Franc-Merlot' 'Torbato' 'Syrah-Petit Verdot'\n",
            " 'Garnacha Blanca' 'Pallagrello' 'Morava' 'Syrah-Mourvèdre' 'Aleatico'\n",
            " 'Carcajolu' 'Kisi' 'Shiraz-Grenache' 'Palomino' 'Grenache-Carignan'\n",
            " 'Nascetta' 'Siria' 'Malbec-Syrah' 'Asprinio' 'Feteascǎ Regalǎ'\n",
            " 'Lambrusco Grasparossa' 'Marselan' 'Tocai Friulano' 'Schiava'\n",
            " 'Alfrocheiro' 'Chardonnay-Semillon' 'Corvina' 'Norton'\n",
            " 'Alicante Bouschet' 'Tokaji' 'Moscadello'\n",
            " 'Cabernet Sauvignon-Tempranillo' 'Carignan' 'Loureiro-Arinto'\n",
            " 'Cabernet-Syrah' 'Sauvignon Blanc-Chardonnay' 'Symphony' 'Edelzwicker'\n",
            " 'Madeira Blend' 'Black Muscat' 'Grenache Noir' 'Durella' 'Xinomavro'\n",
            " 'Tinto del Pais' 'Merlot-Cabernet Sauvignon' 'Cercial'\n",
            " 'Johannisberg Riesling' 'Petite Verdot' 'Passerina' 'Valdiguié'\n",
            " 'Colombard-Sauvignon Blanc' 'Kangoun' 'Loureiro' 'Posip' 'Uva di Troia'\n",
            " 'Gros and Petit Manseng' 'Jacquère' 'Kalecik Karasi' 'Karasakiz'\n",
            " 'Mourvèdre-Syrah' 'Negrette' 'Zierfandler-Rotgipfler' 'Clairette'\n",
            " 'Raboso' 'País' 'Mauzac' 'Pinot Auxerrois' 'Chenin Blanc-Sauvignon Blanc'\n",
            " 'Diamond' 'Marzemino' 'Tinta Barroca' 'Chardonnay-Sauvignon Blanc'\n",
            " 'Castelão' 'Trebbiano Spoletino' 'Teran' 'Trepat' 'Freisa' 'Neuburger'\n",
            " 'Sämling' 'Chasselas' 'Hárslevelü' 'Trincadeira' 'Merlot-Tannat'\n",
            " 'Rkatsiteli' 'Melnik' 'Siegerrebe' 'Trousseau Gris' 'Grenache Blend'\n",
            " 'Gros Manseng' 'Portuguese Rosé' 'Brachetto' 'Mantonico' 'Ekigaïna'\n",
            " 'Muskateller' 'Aligoté' 'Sangiovese Cabernet'\n",
            " 'Touriga Nacional-Cabernet Sauvignon' 'Muscat Blanc' 'Argaman'\n",
            " 'Viognier-Roussanne' 'Pallagrello Bianco' 'Bobal' 'Malvasia Istriana'\n",
            " 'Cabernet Sauvignon-Cabernet Franc' 'Baco Noir' 'Veltliner'\n",
            " 'Tempranillo-Tannat' 'Morillon' 'Touriga Franca' 'Picolit'\n",
            " 'Barbera-Nebbiolo' 'Prieto Picudo' 'Gaglioppo' 'Tokay' 'Sacy'\n",
            " 'Piedirosso' 'Piquepoul Blanc' 'Mansois' 'Chardonnay-Sauvignon'\n",
            " 'Tempranillo-Garnacha' 'Carmenère-Cabernet Sauvignon'\n",
            " 'Chenin Blanc-Viognier' 'Susumaniello' 'Vitovska' 'Orange Muscat'\n",
            " 'Grauburgunder' 'Carignane' 'Moscatel Roxo' 'Tannat-Merlot'\n",
            " 'Nerello Cappuccio' 'Counoise' 'Macabeo' 'Mazuelo' 'Sauvignon-Sémillon'\n",
            " 'Tinta del Pais' 'Vranec' 'Mavrud' \"Cesanese d'Affile\" 'Moscato Giallo'\n",
            " 'Debit' 'Verdil' 'Cabernet' 'Verduzzo Friulano ' 'Treixadura'\n",
            " \"Loin de l'Oeil\" 'Coda di Volpe' 'Grenache-Mourvèdre' 'Forcallà'\n",
            " 'Viura-Verdejo' 'Bombino Bianco' 'Pinot-Chardonnay' 'Syrah-Tempranillo'\n",
            " 'Cabernet Sauvignon-Barbera' 'Merlot-Cabernet' \"Muscat d'Alexandrie\"\n",
            " 'Jaen' 'Tinta del Toro' 'Timorasso' 'Pigato'\n",
            " 'Sangiovese-Cabernet Sauvignon' 'Shiraz-Cabernet'\n",
            " 'Viognier-Gewürztraminer' 'Prunelard' 'Sauvignon Blanc-Chenin Blanc'\n",
            " 'Gros Plant' 'Malbec-Petit Verdot' 'Colombard-Ugni Blanc' 'Grignolino'\n",
            " 'Garnacha-Syrah' 'Rufete' 'Tempranillo-Shiraz' 'Mtsvane'\n",
            " 'Chardonnay-Pinot Gris' 'Marawi' 'Chardonnay-Pinot Blanc' 'Mataro'\n",
            " 'Tinta Cao' 'Blauer Portugieser' 'Ugni Blanc' 'Groppello'\n",
            " 'Semillon-Chardonnay' 'Irsai Oliver' 'Alvarelhão' 'Poulsard'\n",
            " 'Grenache-Shiraz' 'Baga-Touriga Nacional' 'Carineña' 'Pignoletto'\n",
            " 'Muscatel' 'Mavrodaphne' 'Ciliegiolo' 'Viognier-Grenache Blanc'\n",
            " 'Greco Bianco' 'Cabernet Sauvignon-Merlot-Shiraz' 'Sciaccerellu' 'Zelen'\n",
            " 'Alicante' 'Emir' 'Rosenmuskateller' 'Tsolikouri' 'Narince'\n",
            " 'Malbec-Cabernet' 'Touriga' 'Grecanico' 'Carmenère-Syrah'\n",
            " 'Madeleine Angevine' 'Mavroudi' 'Pinot Blanc-Pinot Noir' 'Muscat Hamburg'\n",
            " 'Tempranillo Blanco' 'Casavecchia' 'Pinot Gris-Gewürztraminer'\n",
            " 'White Riesling' 'Tinto Velasco' 'Hondarrabi Zuri' 'Nuragus' 'Xynisteri'\n",
            " 'Kadarka' 'Sauvignon Musqué' 'Roussanne-Marsanne' 'Incrocio Manzoni'\n",
            " 'Terrantez' 'Bual' 'Okuzgozu' 'Rivaner' 'Doña Blanca' 'Graševina'\n",
            " 'Lambrusco Salamino' 'Sangiovese-Syrah' 'Tannat-Cabernet Franc'\n",
            " 'Thrapsathiri' 'Fer Servadou' 'Mission' 'Kekfrankos' 'Cococciola'\n",
            " 'Blauburgunder' 'Marquette' 'Romorantin' 'Verdejo-Sauvignon Blanc'\n",
            " 'Braucol' 'Malvasia-Viura' 'Savatiano' 'Cabernet Franc-Malbec'\n",
            " 'Pallagrello Nero' 'Rebula' 'Vespolina' 'Shiraz-Malbec' 'Rebo'\n",
            " 'Macabeo-Chardonnay' 'Tempranillo-Malbec' 'Tamjanika' 'Trousseau'\n",
            " 'Bacchus' 'Syrah-Malbec' 'Syrah-Cabernet Franc' 'Macabeo-Moscatel'\n",
            " 'Cariñena-Garnacha' 'Plyto' 'Códega do Larinho' 'Sideritis' 'Çalkarası'\n",
            " 'Azal' 'Moscatel Graúdo' 'Viosinho' 'Moschofilero-Chardonnay' 'Paralleda'\n",
            " 'Rara Neagra' 'Malvasia di Candia' 'Maria Gomes' 'Molinara' 'Malvar'\n",
            " 'Airen' 'Erbaluce' 'Muscat of Alexandria' 'Verdosilla' 'Abouriou'\n",
            " 'Pinot Noir-Syrah' 'Nielluciu' 'Malbec-Bonarda' 'Vespaiolo'\n",
            " 'Malbec-Carménère' 'Biancolella' 'Sauvignon Blanc-Verdejo' 'Aidani'\n",
            " 'Garnacha-Monastrell' 'Vinhão' 'Souzao' 'Roter Traminer'\n",
            " 'Moscatel de Alejandría' 'Rolle' 'Tinta Francisca' 'Malvasia Nera'\n",
            " 'Orangetraube' 'Riesling-Chardonnay' 'Žilavka' 'Portuguiser'\n",
            " 'Listán Negro' 'Pinotage-Merlot' 'Muscadine' 'Maria Gomes-Bical'\n",
            " 'Grolleau' 'Zlahtina' 'Syrah-Grenache-Viognier' 'Jacquez' 'Gouveio'\n",
            " 'Canaiolo' 'Carignan-Syrah' 'Bombino Nero' 'Chardonnay-Riesling'\n",
            " 'Malagouzia-Chardonnay' 'Mavrotragano' 'Bovale' 'Frankovka'\n",
            " 'Shiraz-Roussanne' 'Cabernet-Shiraz' 'Syrah-Carignan' 'Elbling'\n",
            " 'Gragnano' 'Garnacha Blend' 'Pinot Blanc-Chardonnay' 'Schwartzriesling'\n",
            " 'Petit Meslier' 'Bastardo' 'Vidadillo' 'Misket'\n",
            " 'Chardonnay Weissburgunder' 'Other' 'Robola' 'Merlot-Shiraz' 'Malagouzia'\n",
            " 'Folle Blanche' 'Malbec Blend' 'Merlot-Syrah' 'Tamianka'\n",
            " 'Cabernet Pfeffer' 'Morio Muskat' 'Rabigato' 'Babić' 'Roviello'\n",
            " 'Yapincak' 'Sauvignonasse' 'Viognier-Marsanne' 'Mandilaria' 'Meseguera'\n",
            " 'Alvarinho-Chardonnay' 'Saperavi-Merlot' 'Pinot Blanc-Viognier'\n",
            " 'Teroldego Rotaliano' 'Biancu Gentile' 'Garnacha-Tempranillo' 'Xinisteri'\n",
            " 'Sauvignon Blanc-Sauvignon Gris' 'Trebbiano di Lugana' 'Albarossa'\n",
            " 'Ryzlink Rýnský' 'Verdeca' 'Cabernet Sauvignon Grenache'\n",
            " 'Tămâioasă Românească' 'Black Monukka' 'Merlot-Grenache' 'Vranac'\n",
            " 'Tempranillo-Syrah' 'Chardonel' 'Silvaner-Traminer' 'Uvalino'\n",
            " 'Merseguera-Sauvignon Blanc' 'Cabernet-Malbec' 'Boğazkere'\n",
            " 'Gelber Traminer' 'Vermentino Nero' 'Cayuga' 'Tinta Amarela'\n",
            " 'Tinta Negra Mole' 'Moscato Rosa' 'Chelois' 'Sauvignon Blanc-Assyrtiko'\n",
            " nan 'Muscadel' 'Shiraz-Tempranillo' 'Roussanne-Grenache Blanc' 'Biancale'\n",
            " 'Ansonica' 'Syrah-Bonarda' 'Durif' 'Franconia' 'Malbec-Tempranillo'\n",
            " 'Nasco' 'Monastrell-Petit Verdot' 'Sirica' 'Vital' 'Espadeiro' 'Apple'\n",
            " 'Pinot Grigio-Sauvignon Blanc' 'Blatina' 'Karalahna' 'Feteasca' 'Sercial'\n",
            " 'Valvin Muscat' 'Malvasia Fina' 'Roditis-Moschofilero' 'St. Vincent'\n",
            " 'Chancellor' 'Premsal' 'Jampal' 'Tokay Pinot Gris' 'Colorino' 'Picapoll'\n",
            " 'Blauburger' 'Tinta Madeira' 'Centesimino' 'Grenache Gris' 'Trajadura'\n",
            " 'Merlot-Petite Verdot' 'Ramisco' 'Catalanesca' 'Garnacha-Cabernet'\n",
            " 'Garnacha-Cariñena' 'Gamza' 'Cabernet Franc-Lemberger'\n",
            " 'Chardonnay-Albariño' 'Shiraz-Mourvèdre' 'Mavrokalavryta' 'Favorita'\n",
            " 'Babosa Negro' 'Tintilia ' 'Dafni' 'Petit Courbu' 'Kotsifali' 'Parraleta'\n",
            " 'Moscato di Noto' 'Roscetto' 'Torontel' 'Otskhanuri Sapere'\n",
            " 'Viognier-Valdiguié' 'Trollinger' 'Tsapournakos' 'Francisa' 'Kuntra'\n",
            " 'Pignolo' 'Caprettone' 'Ondenc' 'Athiri' 'Bobal-Cabernet Sauvignon']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "LKofTJo60FwE"
      },
      "outputs": [],
      "source": [
        "variety_mapping = {\n",
        "    # Whites\n",
        "    'Pinot Gris': 'Pinot Grigio',\n",
        "    'Pinot Grigio/Gris': 'Pinot Grigio',\n",
        "    'Grüner Veltliner': 'Gruner Veltliner',\n",
        "    'Fumé Blanc': 'Sauvignon Blanc',\n",
        "    'Garganega': 'Soave',\n",
        "    'Verdejo-Viura': 'Verdejo',\n",
        "    'Riesling-Chardonnay': 'White Blend',\n",
        "    'Sauvignon Blanc-Semillon': 'White Bordeaux Blend',\n",
        "    'Semillon-Sauvignon Blanc': 'White Bordeaux Blend',\n",
        "    'Trebbiano Spoletino': 'Trebbiano',\n",
        "    'Trebbiano di Lugana': 'Trebbiano',\n",
        "    'Malvasia Bianca': 'Malvasia',\n",
        "    'Verdelho': 'Verdelho',\n",
        "    'Picpoul': 'Piquepoul',\n",
        "    'Alvarinho': 'Albarino',\n",
        "    'Verdicchio': 'Verdicchio',\n",
        "    'Marsanne-Roussanne': 'Rhone White Blend',\n",
        "    'Chardonnay-Sauvignon Blanc': 'White Blend',\n",
        "    'Sauvignon Blanc-Chenin Blanc': 'White Blend',\n",
        "    'Chenin Blanc-Chardonnay': 'White Blend',\n",
        "    'Viognier-Chardonnay': 'White Blend',\n",
        "    'Grenache Blanc': 'Rhone White Blend',\n",
        "    'Assyrtiko': 'Assyrtiko',\n",
        "    'Müller-Thurgau': 'Muller-Thurgau',\n",
        "    'Sylvaner': 'Silvaner',\n",
        "    'Zibibbo': 'Muscat of Alexandria',\n",
        "    'Muscat Blanc à Petits Grains': 'Muscat',\n",
        "    'Prosecco': 'Glera',\n",
        "    'Pinot Bianco': 'Pinot Blanc',\n",
        "    'Sémillon': 'Semillon',\n",
        "\n",
        "    # Reds\n",
        "    'Shiraz': 'Syrah',\n",
        "    'Syrah-Grenache': 'Rhone Red Blend',\n",
        "    'Grenache-Syrah': 'Rhone Red Blend',\n",
        "    'Garnacha': 'Grenache',\n",
        "    'Cabernet Sauvignon-Merlot': 'Bordeaux Blend',\n",
        "    'Merlot-Cabernet Sauvignon': 'Bordeaux Blend',\n",
        "    'Petit Verdot': 'Petit Verdot',\n",
        "    'Tempranillo-Cabernet Sauvignon': 'Tempranillo Blend',\n",
        "    'Malbec-Cabernet Franc': 'Bordeaux Blend',\n",
        "    'Tinta del Pais': 'Tempranillo',\n",
        "    'Tinta Fina': 'Tempranillo',\n",
        "    'Aragonês': 'Tempranillo',\n",
        "    'Cabernet Sauvignon-Syrah': 'Cabernet-Syrah Blend',\n",
        "    'Cabernet Sauvignon-Carmenère': 'Cabernet-Carmenere Blend',\n",
        "    'Monastrell': 'Mourvedre',\n",
        "    'Zinfandel': 'Primitivo',\n",
        "    'Blaufränkisch': 'Blaufrankisch',\n",
        "    'Pinot Nero': 'Pinot Noir',\n",
        "    'Spätburgunder': 'Pinot Noir',\n",
        "    'Ribolla Gialla': 'Ribolla Gialla',\n",
        "    'Frappato': 'Frappato',\n",
        "    'Nero d\\'Avola': 'Nero d\\'Avola',\n",
        "    'Aglianico': 'Aglianico',\n",
        "    'Barbera-Nebbiolo': 'Barbera',\n",
        "    'Cesanese d\\'Affile': 'Cesanese',\n",
        "    'Lagrein': 'Lagrein',\n",
        "\n",
        "    # Sparkling\n",
        "    'Champagne Blend': 'Champagne',\n",
        "    'Sparkling Blend': 'Sparkling Wine',\n",
        "    'Portuguese Sparkling': 'Sparkling Wine',\n",
        "\n",
        "    # Rosés\n",
        "    'Rosé': 'Rose',\n",
        "    'Rosado': 'Rose',\n",
        "    'Portuguese Rosé': 'Rose',\n",
        "\n",
        "    # Fortified and Sweet Wines\n",
        "    'Sherry': 'Sherry',\n",
        "    'Port': 'Port',\n",
        "    'Madeira Blend': 'Madeira',\n",
        "    'Pedro Ximénez': 'Pedro Ximenez',\n",
        "    'Moscatel de Alejandría': 'Muscat of Alexandria',\n",
        "    'Tokaji': 'Tokaji',\n",
        "\n",
        "    # Others and Rare Varieties\n",
        "    'Roussanne': 'Rhone White Blend',\n",
        "    'Marsanne': 'Rhone White Blend',\n",
        "    'Carmenère': 'Carmenere',\n",
        "    'Albariño': 'Albarino',\n",
        "    'Gewürztraminer': 'Gewurztraminer',\n",
        "    'Vermentino': 'Vermentino',\n",
        "    'Viognier': 'Viognier',\n",
        "    'Cortese': 'Cortese (Gavi)',\n",
        "    'Nerello Mascalese': 'Nerello Mascalese',\n",
        "    'Dolcetto': 'Dolcetto',\n",
        "    'Cinsault': 'Cinsault',\n",
        "    'Carignan': 'Carignan',\n",
        "    'Savagnin': 'Savagnin',\n",
        "    'Tannat': 'Tannat',\n",
        "    'Malbec': 'Malbec',\n",
        "    'Petit Manseng': 'Petit Manseng',\n",
        "    'Grenache': 'Grenache',\n",
        "    'Pinotage': 'Pinotage',\n",
        "    'Negroamaro': 'Negroamaro',\n",
        "    'Falanghina': 'Falanghina',\n",
        "    'Vernaccia': 'Vernaccia',\n",
        "    'Primitivo': 'Zinfandel',\n",
        "    'Cabernet Franc': 'Cabernet Franc',\n",
        "    'Cabernet Sauvignon': 'Cabernet Sauvignon',\n",
        "    'Chardonnay': 'Chardonnay',\n",
        "    'Merlot': 'Merlot',\n",
        "    'Sangiovese': 'Sangiovese',\n",
        "    'Nebbiolo': 'Nebbiolo',\n",
        "    'Gamay': 'Gamay',\n",
        "}\n",
        "\n",
        "def consolidate_varieties(variety_name):\n",
        "    if variety_name in variety_mapping:\n",
        "        return variety_mapping[variety_name]\n",
        "    else:\n",
        "        return variety_name\n",
        "\n",
        "\n",
        "df_wine_clean = df_wine.copy()\n",
        "df_wine_clean['variety'] = df_wine_clean['variety'].apply(lambda x: variety_mapping.get(x, x))\n",
        "df_wine_clean.rename(columns={'region_1': 'Subregion', 'region_2': 'Region'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IDwtv3E0FwE"
      },
      "source": [
        "Next, we need to define the set of geography subregions we will use to define our wines. Not too general, not too specific... just right."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the updated column names\n",
        "print(df_wine_clean.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QcHWbJS2VUl",
        "outputId": "50f26fbb-b800-4be0-87b4-439a6274a853"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'country', 'description', 'designation', 'points',\n",
            "       'price', 'province', 'Subregion', 'Region', 'taster_name',\n",
            "       'taster_twitter_handle', 'title', 'variety', 'winery'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "mA48NPuH0FwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b52ece6-00af-4fe4-97de-243adb4c646f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subregion    0\n",
            "Region       0\n",
            "province     0\n",
            "country      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "order_of_geographies = ['Subregion', 'Region', 'province', 'country']\n",
        "\n",
        "# Replace NaN and invalid values with 'none'\n",
        "def replace_nan_for_zero(value):\n",
        "    if str(value).lower() in ['0', 'nan', 'none']:\n",
        "        return 'none'\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "for o in order_of_geographies:\n",
        "    df_wine_clean[o] = df_wine_clean[o].apply(replace_nan_for_zero)\n",
        "\n",
        "# Verify there are no NaN values\n",
        "print(df_wine_clean[order_of_geographies].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_wine_clean.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9HZBwKJ5Y5g",
        "outputId": "0eec45d1-b989-482a-f482-e311cdc30790"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'country', 'description', 'designation', 'points',\n",
            "       'price', 'province', 'Subregion', 'Region', 'taster_name',\n",
            "       'taster_twitter_handle', 'title', 'variety', 'winery'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_wine_clean['geo_normalized'] = (\n",
        "    df_wine_clean['Subregion'] + ', ' +\n",
        "    df_wine_clean['Region'] + ', ' +\n",
        "    df_wine_clean['province'] + ', ' +\n",
        "    df_wine_clean['country']\n",
        ")"
      ],
      "metadata": {
        "id": "HwhrvBJRFexf"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "8yodQxeU0FwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913d6c66-ce27-4dd7-dade-e2d142f282f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       variety country          province Region            Subregion  count\n",
            "0     Abouriou  France  Southwest France   none  Côtes du Marmandais      2\n",
            "4  Agiorgitiko  Greece           Corinth   none                 none      2\n",
            "5  Agiorgitiko  Greece             Nemea   none                 none     51\n",
            "7  Agiorgitiko  Greece       Peloponnese   none                 none      7\n",
            "8    Aglianico   Italy       Italy Other   none        Vino Spumante      2\n"
          ]
        }
      ],
      "source": [
        "# Group by 'Variety', 'Country', 'Province', 'Region', and 'Subregion', and count occurrences\n",
        "variety_geo = df_wine_clean.groupby(['variety', 'country', 'province', 'Region', 'Subregion']).size().reset_index(name='count')\n",
        "\n",
        "# Filter for groups where count > 1\n",
        "variety_geo_sliced = variety_geo.loc[variety_geo['count'] > 1]\n",
        "\n",
        "# Create a new DataFrame with the relevant columns\n",
        "vgeos_df = pd.DataFrame(variety_geo_sliced, columns=['variety', 'country', 'province', 'Region', 'Subregion', 'count'])\n",
        "\n",
        "# Save to CSV\n",
        "vgeos_df.to_csv('varieties_all_geos.csv', index=False)\n",
        "\n",
        "# Preview the result\n",
        "print(vgeos_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-O26oVB7Cw7",
        "outputId": "742e31fe-5733-478f-c91a-0ef704461ff6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYWODzsF7EQl",
        "outputId": "ed0da936-abd8-40dc-97bc-27d9e9d89f8e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'food_word2vec_model.bin.syn1neg.npy', 'drive', 'wine_trigrams.pkl', 'varieties_all_geos.csv', 'food_word2vec_model.bin.wv.vectors.npy', 'food_trigrams.pkl', 'food_word2vec_model.bin', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfgqqAFJ7a98",
        "outputId": "d4eae2a2-3040-4efc-ff68-8f2cf3461fdb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the wine_food_pairing folder\n",
        "file_path = '/content/drive/My Drive/Final Project/wine_food_pairing/varieties_all_geos.csv'\n",
        "\n",
        "# Save the file to the specified folder\n",
        "vgeos_df.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"File saved to: {file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgQ7QFFB7XD6",
        "outputId": "7186d8b5-7696-4a84-c06a-afc40eed8e36"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to: /content/drive/My Drive/Final Project/wine_food_pairing/varieties_all_geos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "u4u23gTt0FwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7bb9ff-d9b7-42bb-d986-867601544b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged DataFrame shape: (126612, 6)\n"
          ]
        }
      ],
      "source": [
        "df_wine_merged = pd.merge(\n",
        "    left=df_wine_clean,\n",
        "    right=vgeos_df,\n",
        "    left_on=['variety', 'country', 'province', 'Region', 'Subregion'],\n",
        "    right_on=['variety', 'country', 'province', 'Region', 'Subregion']\n",
        ")\n",
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = [\n",
        "    'Unnamed: 0', 'designation', 'price', 'province', 'Region',\n",
        "    'Subregion', 'taster_name', 'taster_twitter_handle', 'winery', 'count'\n",
        "]\n",
        "df_wine_merged.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "# Verify the resulting shape\n",
        "print(\"Merged DataFrame shape:\", df_wine_merged.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiC1ofog0FwE"
      },
      "source": [
        "We only want to keep wine types (location + variety) that appear frequently enough in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_wine_merged.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU85SlUN_G_9",
        "outputId": "c20fade7-8202-4a7b-e4d2-8cadc9c14c42"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['country', 'description', 'points', 'title', 'variety'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_wine_clean['geo_normalized'] = (\n",
        "    wine_df_clean['Subregion'] + ', ' +\n",
        "    wine_df_clean['Region'] + ', ' +\n",
        "    wine_df_clean['province'] + ', ' +\n",
        "    wine_df_clean['country']\n",
        ")"
      ],
      "metadata": {
        "id": "ErZglgFXEik7",
        "outputId": "a8024bef-cb87-42f0-9764-83bab448f50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Subregion'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Subregion'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-72e36532aa7b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df_wine_clean['geo_normalized'] = (\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwine_df_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Subregion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mwine_df_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Region'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwine_df_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'province'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwine_df_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Subregion'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "dlmrtfl30FwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "006e1e99-2322-48c7-9d84-05c90029070a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'geo_normalized'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-c97b6b3b4604>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvariety_geos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_wine_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variety'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geo_normalized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mat_least_n_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariety_geos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariety_geos\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_wine_merged_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_wine_merged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat_least_n_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variety'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geo_normalized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variety'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geo_normalized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_wine_merged_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_wine_merged_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'variety'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geo_normalized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_wine_merged_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to supply one of 'by' and 'level'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9183\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   9184\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9185\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'geo_normalized'"
          ]
        }
      ],
      "source": [
        "variety_geos = df_wine_merged.groupby(['variety', 'geo_normalized']).size()\n",
        "at_least_n_types = variety_geos[variety_geos > 30].reset_index()\n",
        "df_wine_merged_filtered = pd.merge(df_wine_merged, at_least_n_types, left_on=['variety', 'geo_normalized'], right_on=['variety', 'geo_normalized'])\n",
        "df_wine_merged_filtered = df_wine_merged_filtered[['title', 'variety', 'geo_normalized', 'description']]\n",
        "print(df_wine_merged_filtered.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pqGPy320FwF"
      },
      "source": [
        "Now, we will extract 7 vectors for every wine:\n",
        "\n",
        "- aroma vector (the aggregate of all the aroma descriptors in a wine)\n",
        "- nonaroma vectors (an aggregate vector for only aroma & non-aroma descriptors matching the core tastes below):\n",
        "    - sweetness\n",
        "    - acid\n",
        "    - salt\n",
        "    - piquant\n",
        "    - fat\n",
        "    - bitter\n",
        "    \n",
        " In our descriptor file, we have defined which normalized descriptors pertain to each nonaroma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw9Ae_-J0FwF"
      },
      "outputs": [],
      "source": [
        "wine_reviews = list(wine_df_merged_filtered['Description'])\n",
        "\n",
        "descriptor_mapping = pd.read_csv('descriptor_mapping_tastes.csv', encoding='latin1').set_index('raw descriptor')\n",
        "\n",
        "core_tastes = ['aroma', 'weight', 'sweet', 'acid', 'salt', 'piquant', 'fat', 'bitter']\n",
        "descriptor_mappings = dict()\n",
        "for c in core_tastes:\n",
        "    if c=='aroma':\n",
        "        descriptor_mapping_filtered=descriptor_mapping.loc[descriptor_mapping['type']=='aroma']\n",
        "    else:\n",
        "        descriptor_mapping_filtered=descriptor_mapping.loc[descriptor_mapping['primary taste']==c]\n",
        "    descriptor_mappings[c] = descriptor_mapping_filtered\n",
        "\n",
        "\n",
        "def return_descriptor_from_mapping(descriptor_mapping, word, core_taste):\n",
        "    if word in list(descriptor_mapping.index):\n",
        "        descriptor_to_return = descriptor_mapping['combined'][word]\n",
        "        return descriptor_to_return\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "review_descriptors = []\n",
        "for review in wine_reviews:\n",
        "    taste_descriptors = []\n",
        "    normalized_review = normalize_text(review)\n",
        "    phrased_review = wine_trigram_model[normalized_review]\n",
        "#     print(phrased_review)\n",
        "\n",
        "    for c in core_tastes:\n",
        "        descriptors_only = [return_descriptor_from_mapping(descriptor_mappings[c], word, c) for word in phrased_review]\n",
        "        no_nones = [str(d).strip() for d in descriptors_only if d is not None]\n",
        "        descriptorized_review = ' '.join(no_nones)\n",
        "        taste_descriptors.append(descriptorized_review)\n",
        "    review_descriptors.append(taste_descriptors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOGm7ho_0FwF"
      },
      "source": [
        "Now we will take the list of descriptors for each wine and its aroma/nonaroma vectors and compute a TF-IDF weighted embedding for each. We will store the results in a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-2RKLx-0FwF"
      },
      "outputs": [],
      "source": [
        "taste_descriptors = []\n",
        "taste_vectors = []\n",
        "\n",
        "for n, taste in enumerate(core_tastes):\n",
        "    print(taste)\n",
        "    taste_words = [r[n] for r in review_descriptors]\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit(taste_words)\n",
        "    dict_of_tfidf_weightings = dict(zip(X.get_feature_names(), X.idf_))\n",
        "\n",
        "    wine_review_descriptors = []\n",
        "    wine_review_vectors = []\n",
        "\n",
        "    for d in taste_words:\n",
        "        descriptor_count = 0\n",
        "        weighted_review_terms = []\n",
        "        terms = d.split(' ')\n",
        "        for term in terms:\n",
        "            if term in dict_of_tfidf_weightings.keys():\n",
        "                tfidf_weighting = dict_of_tfidf_weightings[term]\n",
        "                try:\n",
        "                    word_vector = wine_word2vec_model.wv.get_vector(term).reshape(1, 300)\n",
        "                    weighted_word_vector = tfidf_weighting * word_vector\n",
        "                    weighted_review_terms.append(weighted_word_vector)\n",
        "                    descriptor_count += 1\n",
        "                except:\n",
        "                    continue\n",
        "            else:\n",
        "                continue\n",
        "        try:\n",
        "            review_vector = sum(weighted_review_terms)/len(weighted_review_terms)\n",
        "            review_vector = review_vector[0]\n",
        "        except:\n",
        "            review_vector = np.nan\n",
        "#         terms_and_vec = [terms, review_vector]\n",
        "        wine_review_vectors.append(review_vector)\n",
        "        wine_review_descriptors.append(terms)\n",
        "\n",
        "    taste_vectors.append(wine_review_vectors)\n",
        "    taste_descriptors.append(wine_review_descriptors)\n",
        "\n",
        "\n",
        "taste_vectors_t = list(map(list, zip(*taste_vectors)))\n",
        "taste_descriptors_t = list(map(list, zip(*taste_descriptors)))\n",
        "\n",
        "review_vecs_df = pd.DataFrame(taste_vectors_t, columns=core_tastes)\n",
        "\n",
        "columns_taste_descriptors = [a + '_descriptors' for a in core_tastes]\n",
        "review_descriptors_df = pd.DataFrame(taste_descriptors_t, columns=columns_taste_descriptors)\n",
        "\n",
        "wine_df_vecs = pd.concat([wine_df_merged_filtered, review_descriptors_df, review_vecs_df], axis=1)\n",
        "wine_df_vecs.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqu5mnQo0FwF"
      },
      "source": [
        "If we don't have a nonaroma embedding for one of the wines, we will simply take the average nonaroma embedding for all the wines in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVx98AMp0FwF"
      },
      "outputs": [],
      "source": [
        "# pull the average embedding for the wine attribute across all wines.\n",
        "avg_taste_vecs = dict()\n",
        "for t in core_tastes:\n",
        "    # look at the average embedding for a taste, across all wines that have descriptors for that taste\n",
        "    review_arrays = wine_df_vecs[t].dropna()\n",
        "    average_taste_vec = np.average(review_arrays)\n",
        "    avg_taste_vecs[t] = average_taste_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BUxc6Zq0FwF"
      },
      "source": [
        "Now, let's find the average embedding for each type of wine (aromas and all nonaromas). We have defined the different types of wines by grape variety and geography, keeping only those with a sufficiently large sample size.\n",
        "\n",
        "For each variety, we will pull (i) a 300-dimensional aroma vector, and (ii) 7 non-aroma scalars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3ysQ8zE0FwF"
      },
      "outputs": [],
      "source": [
        "normalized_geos = list(set(zip(wine_df_vecs['Variety'], wine_df_vecs['geo_normalized'])))\n",
        "\n",
        "def subset_wine_vectors(list_of_varieties, wine_attribute):\n",
        "    wine_variety_vectors = []\n",
        "    for v in list_of_varieties:\n",
        "\n",
        "        one_var_only = wine_df_vecs.loc[(wine_df_vecs['Variety'] == v[0]) &\n",
        "                                                (wine_df_vecs['geo_normalized'] == v[1])]\n",
        "        if len(list(one_var_only.index)) < 1 or str(v[1][-1]) == '0':\n",
        "            continue\n",
        "        else:\n",
        "            taste_vecs = list(one_var_only[wine_attribute])\n",
        "            taste_vecs = [avg_taste_vecs[wine_attribute] if 'numpy' not in str(type(x)) else x for x in taste_vecs]\n",
        "            average_variety_vec = np.average(taste_vecs, axis=0)\n",
        "\n",
        "            descriptor_colname = wine_attribute + '_descriptors'\n",
        "            all_descriptors = [i[0] for i in list(one_var_only[descriptor_colname])]\n",
        "            word_freqs = Counter(all_descriptors)\n",
        "            most_common_words = word_freqs.most_common(50)\n",
        "            top_n_words = [(i[0], \"{:.2f}\".format(i[1]/len(taste_vecs))) for i in most_common_words]\n",
        "            top_n_words = [i for i in top_n_words if len(i[0])>2]\n",
        "            wine_variety_vector = [v, average_variety_vec, top_n_words]\n",
        "\n",
        "            wine_variety_vectors.append(wine_variety_vector)\n",
        "\n",
        "    return wine_variety_vectors\n",
        "\n",
        "\n",
        "def pca_wine_variety(list_of_varieties, wine_attribute, pca=True):\n",
        "    wine_var_vectors = subset_wine_vectors(normalized_geos, wine_attribute)\n",
        "\n",
        "    wine_varieties = [str(w[0]).replace('(', '').replace(')', '').replace(\"'\", '').replace('\"', '') for w in wine_var_vectors]\n",
        "    wine_var_vec = [w[1] for w in wine_var_vectors]\n",
        "    if pca:\n",
        "        pca = PCA(1)\n",
        "        wine_var_vec = pca.fit_transform(wine_var_vec)\n",
        "        wine_var_vec = pd.DataFrame(wine_var_vec, index=wine_varieties)\n",
        "    else:\n",
        "        wine_var_vec = pd.Series(wine_var_vec, index=wine_varieties)\n",
        "    wine_var_vec.sort_index(inplace=True)\n",
        "\n",
        "    wine_descriptors = pd.DataFrame([w[2] for w in wine_var_vectors], index=wine_varieties)\n",
        "    wine_descriptors = pd.melt(wine_descriptors.reset_index(), id_vars='index')\n",
        "    wine_descriptors.sort_index(inplace=True)\n",
        "\n",
        "    return wine_var_vec, wine_descriptors\n",
        "\n",
        "taste_dataframes = []\n",
        "# generate the dataframe of aromas vectors as output,\n",
        "aroma_vec, aroma_descriptors = pca_wine_variety(normalized_geos, 'aroma', pca=False)\n",
        "taste_dataframes.append(aroma_vec)\n",
        "\n",
        "# generate the dataframes of nonaroma scalars\n",
        "for tw in core_tastes[1:]:\n",
        "    pca_w_dataframe, nonaroma_descriptors = pca_wine_variety(normalized_geos, tw, pca=True)\n",
        "    taste_dataframes.append(pca_w_dataframe)\n",
        "\n",
        "# combine all the dataframes created above into one\n",
        "all_nonaromas = pd.concat(taste_dataframes, axis=1)\n",
        "all_nonaromas.columns = core_tastes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eULxg8i0FwF"
      },
      "outputs": [],
      "source": [
        "# save the 50 top descriptors for each wine variety as a CSV file. We will us this later to dig deeper into our proposed wine recommendations.\n",
        "\n",
        "aroma_descriptors_copy = aroma_descriptors.copy()\n",
        "aroma_descriptors_copy.set_index('index', inplace=True)\n",
        "aroma_descriptors_copy.dropna(inplace=True)\n",
        "\n",
        "aroma_descriptors_copy = pd.DataFrame(aroma_descriptors_copy['value'].tolist(), index=aroma_descriptors_copy.index)\n",
        "aroma_descriptors_copy.columns = ['descriptors', 'relative_frequency']\n",
        "aroma_descriptors_copy.to_csv('wine_variety_descriptors.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4jjPIgx0FwF"
      },
      "source": [
        "At the moment, it's hard to interpret the nonaroma scalars. To allow for greater interpretability, we will normalize the nonaroma scalars between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "2gqerbSM0FwG"
      },
      "outputs": [],
      "source": [
        "def normalize(df, cols_to_normalize):\n",
        "    for feature_name in cols_to_normalize:\n",
        "        print(feature_name)\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()\n",
        "        df[feature_name] = df[feature_name].apply(lambda x: (x- min_value)/(max_value-min_value))\n",
        "#         (df[feature_name] - min_value) / (max_value - min_value)\n",
        "    return df\n",
        "\n",
        "all_nonaromas_normalized = normalize(all_nonaromas, cols_to_normalize=core_tastes[1:])\n",
        "all_nonaromas_normalized.to_csv('wine_aromas_nonaromas.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubDnH0SU0FwG"
      },
      "source": [
        "### 3. Preparing our Food Dataset\n",
        "\n",
        "Now that we have our wine aroma vectors and the nonaroma scalars, we can turn our attention to food.\n",
        "\n",
        "We will want to generate nonaroma vectors for any type of food that we want a wine pairing with. For food, we don't have the luxury of being able to define nonaroma vs. aroma descriptors, so the approach we take will be slightly different:\n",
        "\n",
        "The aroma vector will be the full food embedding.\n",
        "\n",
        "We will define an embedding for each of our core nonaromas (sweet, acid, salt, piquant, fat and bitter), and the weight/body of the food. We will define the maximum distance between each of the nonaroma embeddings and a range of commonly appearing foods. The foods that least and most resemble each nonaroma will eventually allow us to create a normalized scale between 0 (very dissimilar) and 1 (very similar) to say how much a food reflects each nonaroma.\n",
        "\n",
        "First, let's load this list of common foods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfeHrkeC0FwG"
      },
      "outputs": [],
      "source": [
        "foods = pd.read_csv('list_of_foods.csv')\n",
        "foods_list = list(foods['Food'])\n",
        "foods_list_normalized = [normalize_text(f) for f in foods_list]\n",
        "foods_list_preprocessed = [food_trigram_model[f][0] for f in foods_list_normalized]\n",
        "foods_list_preprocessed = list(set(foods_list_preprocessed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg_YmMyM0FwG"
      },
      "source": [
        "Load the word embedding for each food in the list of sample foods, and save to a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6df4xSA0FwG"
      },
      "outputs": [],
      "source": [
        "foods_vecs = dict()\n",
        "\n",
        "word_vectors = wine_word2vec_model.wv\n",
        "for f in foods_list_preprocessed:\n",
        "    try:\n",
        "        food_vec = word_vectors[f]\n",
        "        foods_vecs[f] = food_vec\n",
        "    except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROb5mydF0FwG"
      },
      "source": [
        "Now, we can define the nonaroma embeddings + the weight embedding as the average of foods that represent each nonaroma characteristic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdDR59tB0FwG"
      },
      "outputs": [],
      "source": [
        "from scipy import spatial\n",
        "\n",
        "core_tastes_revised = {'weight': ['heavy', 'cassoulet', 'cassoulet', 'full_bodied', 'thick', 'milk', 'fat', 'mincemeat', 'steak', 'bold', 'pizza', 'pasta', 'creamy', 'bread'],\n",
        "                       'sweet': ['sweet', 'sugar', 'cake', 'mango', 'stevia'],\n",
        "                       'acid': ['acid', 'sour', 'vinegar', 'yoghurt', 'cevich', 'cevich'],\n",
        "                       'salt': ['salty', 'salty', 'parmesan', 'oyster', 'pizza', 'bacon', 'cured_meat', 'sausage', 'potato_chip'],\n",
        "                       'piquant': ['spicy'],\n",
        "                       'fat': ['fat', 'fried', 'creamy', 'cassoulet', 'foie_gras', 'buttery', 'cake', 'foie_gras', 'sausage', 'brie', 'carbonara'],\n",
        "                       'bitter': ['bitter', 'kale']\n",
        "                      }\n",
        "\n",
        "average_taste_vecs = dict()\n",
        "core_tastes_distances = dict()\n",
        "for taste, keywords in core_tastes_revised.items():\n",
        "\n",
        "    all_keyword_vecs = []\n",
        "    for keyword in keywords:\n",
        "        c_vec = word_vectors[keyword]\n",
        "        all_keyword_vecs.append(c_vec)\n",
        "\n",
        "    avg_taste_vec = np.average(all_keyword_vecs, axis=0)\n",
        "    average_taste_vecs[taste] = avg_taste_vec\n",
        "\n",
        "    taste_distances = dict()\n",
        "    for k, v in foods_vecs.items():\n",
        "        similarity = 1- spatial.distance.cosine(avg_taste_vec, v)\n",
        "        taste_distances[k] = similarity\n",
        "\n",
        "    core_tastes_distances[taste] = taste_distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw5tSkk70FwG"
      },
      "source": [
        "We can now find out which foods most and least resemble each nonaroma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "qfls67gB0FwG"
      },
      "outputs": [],
      "source": [
        "food_nonaroma_infos = dict()\n",
        "# for each core taste, identify the food item that is farthest and closest. We will need this to create a normalized scale between 0 and 1\n",
        "for key, value in core_tastes_revised.items():\n",
        "    dict_taste = dict()\n",
        "    farthest = min(core_tastes_distances[key], key=core_tastes_distances[key].get)\n",
        "    farthest_distance = core_tastes_distances[key][farthest]\n",
        "    closest = max(core_tastes_distances[key], key=core_tastes_distances[key].get)\n",
        "    closest_distance = core_tastes_distances[key][closest]\n",
        "    print(key, farthest, closest)\n",
        "    dict_taste['farthest'] = farthest_distance\n",
        "    dict_taste['closest'] = closest_distance\n",
        "    dict_taste['average_vec'] = average_taste_vecs[key]\n",
        "    food_nonaroma_infos[key] = dict_taste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPTsS-6G0FwG"
      },
      "source": [
        "Now, let's save the average embedding for each nonaroma, as well as the minimum and maximum distance to each nonaroma embedding - we will use these to scale the nonaroma scalars that we obtain for any foods we try to pair wine with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FrFgF-50FwG"
      },
      "outputs": [],
      "source": [
        "food_nonaroma_infos_df = pd.DataFrame(food_nonaroma_infos).T\n",
        "food_nonaroma_infos_df.to_csv('average_nonaroma_vectors.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw8JH5MO0FwG"
      },
      "source": [
        "We have all the pieces we need to build our wine recommendations. We will continue with this in a separate notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}