{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPvmjm340azr",
        "outputId": "833f0681-b22f-41c4-b3d9-ec6deb7567a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxduMSKe0Fv-",
        "outputId": "b2f7b12b-dd1f-4ba8-db02-e5c63a3e5f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "# from operator import itemgetter\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXmg02oT8Eqj",
        "outputId": "2484f63d-2440-4eb5-e82d-5e6f1a117503"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sample_text = \"This is a test. Let's see if this works.\"\n",
        "print(sent_tokenize(sample_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h8RFXlI3TsG",
        "outputId": "d7e7c11d-1840-4590-95a1-3708d17e582b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This is a test.', \"Let's see if this works.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"zynicide/wine-reviews\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# List files in the dataset directory\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXTRlr5e0m5M",
        "outputId": "6a56b1c9-fe24-4145-9bd2-cd9073f281a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/zynicide/wine-reviews?dataset_version_number=4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50.9M/50.9M [00:00<00:00, 65.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/zynicide/wine-reviews/versions/4\n",
            "['winemag-data-130k-v2.csv', 'winemag-data-130k-v2.json', 'winemag-data_first150k.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww-jJlhk0Fv_"
      },
      "source": [
        "First, import the wine dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the CSV file\n",
        "csv_path = os.path.join(path, \"winemag-data-130k-v2.csv\")\n",
        "\n",
        "# Load the CSV file\n",
        "df_wine = pd.read_csv(csv_path)\n",
        "\n",
        "# Preview the data\n",
        "print(df_wine.head())\n",
        "print(df_wine.columns)\n",
        "print(df_wine.info())\n",
        "print(df_wine.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vTefZRP0oea",
        "outputId": "0aae1736-c243-47f0-c45f-8e82ccdd5447"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0   country                                        description  \\\n",
            "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
            "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
            "2           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
            "3           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
            "4           4        US  Much like the regular bottling from 2012, this...   \n",
            "\n",
            "                          designation  points  price           province  \\\n",
            "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
            "1                            Avidagos      87   15.0              Douro   \n",
            "2                                 NaN      87   14.0             Oregon   \n",
            "3                Reserve Late Harvest      87   13.0           Michigan   \n",
            "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
            "\n",
            "              region_1           region_2         taster_name  \\\n",
            "0                 Etna                NaN       Kerin O’Keefe   \n",
            "1                  NaN                NaN          Roger Voss   \n",
            "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
            "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
            "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
            "\n",
            "  taster_twitter_handle                                              title  \\\n",
            "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
            "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
            "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
            "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
            "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
            "\n",
            "          variety               winery  \n",
            "0     White Blend              Nicosia  \n",
            "1  Portuguese Red  Quinta dos Avidagos  \n",
            "2      Pinot Gris            Rainstorm  \n",
            "3        Riesling           St. Julian  \n",
            "4      Pinot Noir         Sweet Cheeks  \n",
            "Index(['Unnamed: 0', 'country', 'description', 'designation', 'points',\n",
            "       'price', 'province', 'region_1', 'region_2', 'taster_name',\n",
            "       'taster_twitter_handle', 'title', 'variety', 'winery'],\n",
            "      dtype='object')\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 129971 entries, 0 to 129970\n",
            "Data columns (total 14 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   Unnamed: 0             129971 non-null  int64  \n",
            " 1   country                129908 non-null  object \n",
            " 2   description            129971 non-null  object \n",
            " 3   designation            92506 non-null   object \n",
            " 4   points                 129971 non-null  int64  \n",
            " 5   price                  120975 non-null  float64\n",
            " 6   province               129908 non-null  object \n",
            " 7   region_1               108724 non-null  object \n",
            " 8   region_2               50511 non-null   object \n",
            " 9   taster_name            103727 non-null  object \n",
            " 10  taster_twitter_handle  98758 non-null   object \n",
            " 11  title                  129971 non-null  object \n",
            " 12  variety                129970 non-null  object \n",
            " 13  winery                 129971 non-null  object \n",
            "dtypes: float64(1), int64(2), object(11)\n",
            "memory usage: 13.9+ MB\n",
            "None\n",
            "Unnamed: 0                   0\n",
            "country                     63\n",
            "description                  0\n",
            "designation              37465\n",
            "points                       0\n",
            "price                     8996\n",
            "province                    63\n",
            "region_1                 21247\n",
            "region_2                 79460\n",
            "taster_name              26244\n",
            "taster_twitter_handle    31213\n",
            "title                        0\n",
            "variety                      1\n",
            "winery                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "source": [
        "Then, the food dataset."
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "jh1CNip40FwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path2 = kagglehub.dataset_download(\"snap/amazon-fine-food-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path2)"
      ],
      "metadata": {
        "id": "9XM4aZCF1P_Q",
        "outputId": "c9bb2559-9f0b-407d-9a6e-2890792fbf4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/snap/amazon-fine-food-reviews?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 242M/242M [00:05<00:00, 47.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/snap/amazon-fine-food-reviews/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the CSV file\n",
        "csv_path2 = os.path.join(path2, \"Reviews.csv\")\n",
        "\n",
        "# Load the CSV file\n",
        "df_food = pd.read_csv(csv_path2)\n",
        "\n",
        "# Preview the data\n",
        "print(df_food.head())\n",
        "print(df_food.columns)\n",
        "print(df_food.info())\n",
        "print(df_food.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqpo7Fqb0ySf",
        "outputId": "49c73a94-99e3-428d-de15-e067a9e06b55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id   ProductId          UserId                      ProfileName  \\\n",
            "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
            "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
            "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
            "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
            "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
            "0                     1                       1      5  1303862400   \n",
            "1                     0                       0      1  1346976000   \n",
            "2                     1                       1      4  1219017600   \n",
            "3                     3                       3      2  1307923200   \n",
            "4                     0                       0      5  1350777600   \n",
            "\n",
            "                 Summary                                               Text  \n",
            "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
            "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
            "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
            "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
            "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
            "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
            "      dtype='object')\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568428 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n",
            "None\n",
            "Id                         0\n",
            "ProductId                  0\n",
            "UserId                     0\n",
            "ProfileName               26\n",
            "HelpfulnessNumerator       0\n",
            "HelpfulnessDenominator     0\n",
            "Score                      0\n",
            "Time                       0\n",
            "Summary                   27\n",
            "Text                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUpCe0rl0FwB"
      },
      "source": [
        "### 1. Training our Word Embeddings\n",
        "\n",
        "First, we need to train a Word2Vec model on all the words in our corpus. We will process our wine and food terms separately - some of the wine terms will be standardized to account for commonalities in the colorful language of the world of wine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3P6n7o9k0FwB"
      },
      "outputs": [],
      "source": [
        "wine_reviews_list = list(df_wine['description'])\n",
        "food_reviews_list = list(df_food['Text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBjtKrxc0FwC"
      },
      "source": [
        "To begin, we need to tokenize the terms in our corpus (wine and food)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bqd3Bl60FwC",
        "outputId": "af63d7c1-76cc-487a-e294-d4d675839242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aromas include tropical fruit, broom, brimstone and dried herb.', \"The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\"]\n",
            "['I have bought several of the Vitality canned dog food products and have found them all to be of good quality.', 'The product looks more like a stew than a processed meat and it smells better.']\n"
          ]
        }
      ],
      "source": [
        "full_wine_reviews_list = [str(r) for r in wine_reviews_list]\n",
        "full_wine_corpus = ' '.join(full_wine_reviews_list)\n",
        "wine_sentences_tokenized = sent_tokenize(full_wine_corpus)\n",
        "\n",
        "full_food_reviews_list = [str(r) for r in food_reviews_list]\n",
        "full_food_corpus = ' '.join(full_food_reviews_list)\n",
        "food_sentences_tokenized = sent_tokenize(full_food_corpus)\n",
        "\n",
        "print(wine_sentences_tokenized[:2])\n",
        "print(food_sentences_tokenized[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXSP9DQo0FwC"
      },
      "source": [
        "Next, the text in each sentence is normalized (tokenize, remove punctuation and remove stopwords)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lDS8Zq5l0FwC"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "punctuation_table = str.maketrans({key: None for key in string.punctuation})\n",
        "sno = SnowballStemmer('english')\n",
        "\n",
        "def normalize_text(raw_text):\n",
        "    try:\n",
        "        word_list = word_tokenize(raw_text)\n",
        "        normalized_sentence = []\n",
        "        for w in word_list:\n",
        "            try:\n",
        "                w = str(w)\n",
        "                lower_case_word = str.lower(w)\n",
        "                stemmed_word = sno.stem(lower_case_word)\n",
        "                no_punctuation = stemmed_word.translate(punctuation_table)\n",
        "                if len(no_punctuation) > 1 and no_punctuation not in stop_words:\n",
        "                    normalized_sentence.append(no_punctuation)\n",
        "            except:\n",
        "                continue\n",
        "        return normalized_sentence\n",
        "    except:\n",
        "        return ''\n",
        "\n",
        "normalized_wine_sentences = []\n",
        "for s in wine_sentences_tokenized:\n",
        "    normalized_text = normalize_text(s)\n",
        "    normalized_wine_sentences.append(normalized_text)\n",
        "\n",
        "normalized_food_sentences = []\n",
        "for s in food_sentences_tokenized:\n",
        "    normalized_text = normalize_text(s)\n",
        "    normalized_food_sentences.append(normalized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmzXUI5W0FwD"
      },
      "source": [
        "Not all of the terms we are interested in are single words. Some of the terms are phrases, consisting of two (or more!) words. An example of this might be 'high tannin'. We can use gensim's Phrases feature to extract all the most relevant bi- and tri-grams from our corpus.\n",
        "\n",
        "We will train a separate trigram model for wine and for food."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rIw0hg_t0FwD"
      },
      "outputs": [],
      "source": [
        "# first, take care of the wine trigrams\n",
        "wine_bigram_model = Phrases(normalized_wine_sentences, min_count=100)\n",
        "wine_bigrams = [wine_bigram_model[line] for line in normalized_wine_sentences]\n",
        "wine_trigram_model = Phrases(wine_bigrams, min_count=50)\n",
        "phrased_wine_sentences = [wine_trigram_model[line] for line in wine_bigrams]\n",
        "wine_trigram_model.save('wine_trigrams.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### now, do the same for food\n",
        "food_bigram_model = Phrases(normalized_food_sentences, min_count=100)\n",
        "food_bigrams = [food_bigram_model[sent] for sent in normalized_food_sentences]\n",
        "food_trigram_model = Phrases(food_bigrams, min_count=50)\n",
        "phrased_food_sentences = [food_trigram_model[sent] for sent in food_bigrams]\n",
        "food_trigram_model.save('food_trigrams.pkl')"
      ],
      "metadata": {
        "id": "g8DthWGhPdgJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL2O7n2u0FwD"
      },
      "source": [
        "If the trigram model has already been trained, simply retrieve it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8Rk2Ti3g0FwD"
      },
      "outputs": [],
      "source": [
        "wine_trigram_model = Phraser.load('wine_trigrams.pkl')\n",
        "food_trigram_model = Phraser.load('food_trigrams.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLuyBy_O0FwD"
      },
      "source": [
        "Now for the most important part: leveraging existing wine theory, the work of others like Bernard Chen, wine descriptor mappings and the UC Davis wine wheel, the top 5000 most frequent wine terms were reviewed to (i) determine whether they are a descriptor that can be derived by blind tasting, and (ii) whether they are informative (judgments like 'tasty' and 'great' are not considered to be informative). The roughly 1000 descriptors that remain were then mapped onto a normalized descriptor, a category and a class:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BI2G41LVQ6Un",
        "outputId": "1c5c80e5-e672-4bc0-b68c-9baeb5899ee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KcX6eKcA0FwD"
      },
      "outputs": [],
      "source": [
        "descriptor_mapping = pd.read_csv('/content/drive/My Drive/Final Project/wine_food_pairing/descriptor_mapping.csv', encoding='latin1').set_index('raw descriptor')\n",
        "\n",
        "def return_mapped_descriptor(word, mapping):\n",
        "    if word in list(mapping.index):\n",
        "        normalized_word = mapping.at[word, 'level_3']\n",
        "        return normalized_word\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "normalized_wine_sentences = []\n",
        "for sent in phrased_wine_sentences:\n",
        "    normalized_wine_sentence = []\n",
        "    for word in sent:\n",
        "        normalized_word = return_mapped_descriptor(word, descriptor_mapping)\n",
        "        normalized_wine_sentence.append(str(normalized_word))\n",
        "    normalized_wine_sentences.append(normalized_wine_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9IcR_Nu0FwD"
      },
      "source": [
        "We will go through the same process for food, but without normalizing the nonaroma descriptors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cU31n30z0FwD"
      },
      "outputs": [],
      "source": [
        "aroma_descriptor_mapping = descriptor_mapping.loc[descriptor_mapping['type'] == 'aroma']\n",
        "normalized_food_sentences = []\n",
        "for sent in phrased_food_sentences:\n",
        "    normalized_food_sentence = []\n",
        "    for word in sent:\n",
        "        normalized_word = return_mapped_descriptor(word, aroma_descriptor_mapping)\n",
        "        normalized_food_sentence.append(str(normalized_word))\n",
        "    normalized_food_sentences.append(normalized_food_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiSf78hZ0FwD"
      },
      "source": [
        "Now, let's combine the wine dataset with our food dataset so we can train our embeddings. We want to make sure that the food and wine embeddings are calculated in the same feature space so that we can compute similarity vectors later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "55C8f3mF0FwD"
      },
      "outputs": [],
      "source": [
        "normalized_sentences = normalized_wine_sentences + normalized_food_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7MbSqLn0FwE"
      },
      "source": [
        "We are ready to train our Word2Vec model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pRn-YNZ_0FwE",
        "outputId": "e35fedfa-bc99-4638-dae6-eff110d4ceb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Word2Vec.__init__() got an unexpected keyword argument 'size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-cab1bf7edff8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwine_word2vec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwine_word2vec_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwine_word2vec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'food_word2vec_model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Word2Vec.__init__() got an unexpected keyword argument 'size'"
          ]
        }
      ],
      "source": [
        "wine_word2vec_model = Word2Vec(normalized_sentences, size=300, min_count=8, iter=15)\n",
        "print(wine_word2vec_model)\n",
        "\n",
        "wine_word2vec_model.save('food_word2vec_model.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN8DbtRB0FwE"
      },
      "outputs": [],
      "source": [
        "# if the word2vec model has already been trained, simply load it\n",
        "wine_word2vec_model = Word2Vec.load(\"food_word2vec_model.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zezDOE8j0FwE"
      },
      "source": [
        "### 2. Preprocessing our Wine Dataset\n",
        "\n",
        "We can now turn our attention to our wine dataset. Descriptions for a single wine are unlikely to contain sufficient information about all the nonaromas and aromas to yield consistent and reliable pairing recommendations. As such, we will produce recommendations at the grape variety & subregion level.\n",
        "\n",
        "First, let's normalize the names of the grape varieties in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the unique values in the 'variety' column\n",
        "unique_varieties = df_wine['variety'].unique()\n",
        "print(f\"Unique grape varieties ({len(unique_varieties)} total):\")\n",
        "print(unique_varieties)"
      ],
      "metadata": {
        "id": "HxV2Pdf6t5Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKofTJo60FwE"
      },
      "outputs": [],
      "source": [
        "variety_mapping = {\n",
        "    # Whites\n",
        "    'Pinot Gris': 'Pinot Grigio',\n",
        "    'Pinot Grigio/Gris': 'Pinot Grigio',\n",
        "    'Grüner Veltliner': 'Gruner Veltliner',\n",
        "    'Fumé Blanc': 'Sauvignon Blanc',\n",
        "    'Garganega': 'Soave',\n",
        "    'Verdejo-Viura': 'Verdejo',\n",
        "    'Riesling-Chardonnay': 'White Blend',\n",
        "    'Sauvignon Blanc-Semillon': 'White Bordeaux Blend',\n",
        "    'Semillon-Sauvignon Blanc': 'White Bordeaux Blend',\n",
        "    'Trebbiano Spoletino': 'Trebbiano',\n",
        "    'Trebbiano di Lugana': 'Trebbiano',\n",
        "    'Malvasia Bianca': 'Malvasia',\n",
        "    'Verdelho': 'Verdelho',\n",
        "    'Picpoul': 'Piquepoul',\n",
        "    'Alvarinho': 'Albarino',\n",
        "    'Verdicchio': 'Verdicchio',\n",
        "    'Marsanne-Roussanne': 'Rhone White Blend',\n",
        "    'Chardonnay-Sauvignon Blanc': 'White Blend',\n",
        "    'Sauvignon Blanc-Chenin Blanc': 'White Blend',\n",
        "    'Chenin Blanc-Chardonnay': 'White Blend',\n",
        "    'Viognier-Chardonnay': 'White Blend',\n",
        "    'Grenache Blanc': 'Rhone White Blend',\n",
        "    'Assyrtiko': 'Assyrtiko',\n",
        "    'Müller-Thurgau': 'Muller-Thurgau',\n",
        "    'Sylvaner': 'Silvaner',\n",
        "    'Zibibbo': 'Muscat of Alexandria',\n",
        "    'Muscat Blanc à Petits Grains': 'Muscat',\n",
        "    'Prosecco': 'Glera',\n",
        "    'Pinot Bianco': 'Pinot Blanc',\n",
        "    'Sémillon': 'Semillon',\n",
        "\n",
        "    # Reds\n",
        "    'Shiraz': 'Syrah',\n",
        "    'Syrah-Grenache': 'Rhone Red Blend',\n",
        "    'Grenache-Syrah': 'Rhone Red Blend',\n",
        "    'Garnacha': 'Grenache',\n",
        "    'Cabernet Sauvignon-Merlot': 'Bordeaux Blend',\n",
        "    'Merlot-Cabernet Sauvignon': 'Bordeaux Blend',\n",
        "    'Petit Verdot': 'Petit Verdot',\n",
        "    'Tempranillo-Cabernet Sauvignon': 'Tempranillo Blend',\n",
        "    'Malbec-Cabernet Franc': 'Bordeaux Blend',\n",
        "    'Tinta del Pais': 'Tempranillo',\n",
        "    'Tinta Fina': 'Tempranillo',\n",
        "    'Aragonês': 'Tempranillo',\n",
        "    'Cabernet Sauvignon-Syrah': 'Cabernet-Syrah Blend',\n",
        "    'Cabernet Sauvignon-Carmenère': 'Cabernet-Carmenere Blend',\n",
        "    'Monastrell': 'Mourvedre',\n",
        "    'Zinfandel': 'Primitivo',\n",
        "    'Blaufränkisch': 'Blaufrankisch',\n",
        "    'Pinot Nero': 'Pinot Noir',\n",
        "    'Spätburgunder': 'Pinot Noir',\n",
        "    'Ribolla Gialla': 'Ribolla Gialla',\n",
        "    'Frappato': 'Frappato',\n",
        "    'Nero d\\'Avola': 'Nero d\\'Avola',\n",
        "    'Aglianico': 'Aglianico',\n",
        "    'Barbera-Nebbiolo': 'Barbera',\n",
        "    'Cesanese d\\'Affile': 'Cesanese',\n",
        "    'Lagrein': 'Lagrein',\n",
        "\n",
        "    # Sparkling\n",
        "    'Champagne Blend': 'Champagne',\n",
        "    'Sparkling Blend': 'Sparkling Wine',\n",
        "    'Portuguese Sparkling': 'Sparkling Wine',\n",
        "\n",
        "    # Rosés\n",
        "    'Rosé': 'Rose',\n",
        "    'Rosado': 'Rose',\n",
        "    'Portuguese Rosé': 'Rose',\n",
        "\n",
        "    # Fortified and Sweet Wines\n",
        "    'Sherry': 'Sherry',\n",
        "    'Port': 'Port',\n",
        "    'Madeira Blend': 'Madeira',\n",
        "    'Pedro Ximénez': 'Pedro Ximenez',\n",
        "    'Moscatel de Alejandría': 'Muscat of Alexandria',\n",
        "    'Tokaji': 'Tokaji',\n",
        "\n",
        "    # Others and Rare Varieties\n",
        "    'Roussanne': 'Rhone White Blend',\n",
        "    'Marsanne': 'Rhone White Blend',\n",
        "    'Carmenère': 'Carmenere',\n",
        "    'Albariño': 'Albarino',\n",
        "    'Gewürztraminer': 'Gewurztraminer',\n",
        "    'Vermentino': 'Vermentino',\n",
        "    'Viognier': 'Viognier',\n",
        "    'Cortese': 'Cortese (Gavi)',\n",
        "    'Nerello Mascalese': 'Nerello Mascalese',\n",
        "    'Dolcetto': 'Dolcetto',\n",
        "    'Cinsault': 'Cinsault',\n",
        "    'Carignan': 'Carignan',\n",
        "    'Savagnin': 'Savagnin',\n",
        "    'Tannat': 'Tannat',\n",
        "    'Malbec': 'Malbec',\n",
        "    'Petit Manseng': 'Petit Manseng',\n",
        "    'Grenache': 'Grenache',\n",
        "    'Pinotage': 'Pinotage',\n",
        "    'Negroamaro': 'Negroamaro',\n",
        "    'Falanghina': 'Falanghina',\n",
        "    'Vernaccia': 'Vernaccia',\n",
        "    'Primitivo': 'Zinfandel',\n",
        "    'Cabernet Franc': 'Cabernet Franc',\n",
        "    'Cabernet Sauvignon': 'Cabernet Sauvignon',\n",
        "    'Chardonnay': 'Chardonnay',\n",
        "    'Merlot': 'Merlot',\n",
        "    'Sangiovese': 'Sangiovese',\n",
        "    'Nebbiolo': 'Nebbiolo',\n",
        "    'Gamay': 'Gamay',\n",
        "}\n",
        "\n",
        "def consolidate_varieties(variety_name):\n",
        "    if variety_name in variety_mapping:\n",
        "        return variety_mapping[variety_name]\n",
        "    else:\n",
        "        return variety_name\n",
        "\n",
        "\n",
        "df_wine_clean = df_wine.copy()\n",
        "df_wine_clean['variety'] = df_wine_clean['variety'].apply(lambda x: variety_mapping.get(x, x))\n",
        "df_wine_clean.rename(columns={'region_1': 'Subregion', 'region_2': 'Region'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IDwtv3E0FwE"
      },
      "source": [
        "Next, we need to define the set of geography subregions we will use to define our wines. Not too general, not too specific... just right."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the updated column names\n",
        "print(df_wine_clean.columns)"
      ],
      "metadata": {
        "id": "0QcHWbJS2VUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA48NPuH0FwE"
      },
      "outputs": [],
      "source": [
        "order_of_geographies = ['Subregion', 'Region', 'province', 'country']\n",
        "\n",
        "# Replace NaN and invalid values with 'none'\n",
        "def replace_nan_for_zero(value):\n",
        "    if str(value).lower() in ['0', 'nan', 'none']:\n",
        "        return 'none'\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "for o in order_of_geographies:\n",
        "    df_wine_clean[o] = df_wine_clean[o].apply(replace_nan_for_zero)\n",
        "\n",
        "# Verify there are no NaN values\n",
        "print(df_wine_clean[order_of_geographies].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_wine_clean.columns)"
      ],
      "metadata": {
        "id": "j9HZBwKJ5Y5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_wine_clean['geo_normalized'] = (\n",
        "    df_wine_clean['Subregion'] + ', ' +\n",
        "    df_wine_clean['Region'] + ', ' +\n",
        "    df_wine_clean['province'] + ', ' +\n",
        "    df_wine_clean['country']\n",
        ")"
      ],
      "metadata": {
        "id": "HwhrvBJRFexf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yodQxeU0FwE"
      },
      "outputs": [],
      "source": [
        "# Group by 'Variety', 'Country', 'Province', 'Region', and 'Subregion', and count occurrences\n",
        "variety_geo = df_wine_clean.groupby(['variety', 'country', 'province', 'Region', 'Subregion']).size().reset_index(name='count')\n",
        "\n",
        "# Filter for groups where count > 1\n",
        "variety_geo_sliced = variety_geo.loc[variety_geo['count'] > 1]\n",
        "\n",
        "# Create a new DataFrame with the relevant columns\n",
        "vgeos_df = pd.DataFrame(variety_geo_sliced, columns=['variety', 'country', 'province', 'Region', 'Subregion', 'count'])\n",
        "\n",
        "# Save to CSV\n",
        "vgeos_df.to_csv('varieties_all_geos.csv', index=False)\n",
        "\n",
        "# Preview the result\n",
        "print(vgeos_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "t-O26oVB7Cw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir())"
      ],
      "metadata": {
        "id": "UYWODzsF7EQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pfgqqAFJ7a98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the wine_food_pairing folder\n",
        "file_path = '/content/drive/My Drive/Final Project/wine_food_pairing/varieties_all_geos.csv'\n",
        "\n",
        "# Save the file to the specified folder\n",
        "vgeos_df.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"File saved to: {file_path}\")"
      ],
      "metadata": {
        "id": "BgQ7QFFB7XD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4u23gTt0FwE"
      },
      "outputs": [],
      "source": [
        "df_wine_merged = pd.merge(\n",
        "    left=df_wine_clean,\n",
        "    right=vgeos_df,\n",
        "    left_on=['variety', 'country', 'province', 'Region', 'Subregion'],\n",
        "    right_on=['variety', 'country', 'province', 'Region', 'Subregion']\n",
        ")\n",
        "\n",
        "# Drop unnecessary columns\n",
        "columns_to_drop = [\n",
        "    'Unnamed: 0', 'designation', 'price', 'province', 'Region',\n",
        "    'Subregion', 'taster_name', 'taster_twitter_handle', 'winery', 'count'\n",
        "]\n",
        "df_wine_merged.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "# Verify the resulting shape\n",
        "print(\"Merged DataFrame shape:\", df_wine_merged.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiC1ofog0FwE"
      },
      "source": [
        "We only want to keep wine types (location + variety) that appear frequently enough in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_wine_merged.columns)"
      ],
      "metadata": {
        "id": "ZU85SlUN_G_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlmrtfl30FwE"
      },
      "outputs": [],
      "source": [
        "variety_geos = df_wine_merged.groupby(['variety', 'geo_normalized']).size()\n",
        "at_least_n_types = variety_geos[variety_geos > 30].reset_index()\n",
        "df_wine_merged_filtered = pd.merge(df_wine_merged, at_least_n_types, left_on=['variety', 'geo_normalized'], right_on=['variety', 'geo_normalized'])\n",
        "df_wine_merged_filtered = df_wine_merged_filtered[['title', 'variety', 'geo_normalized', 'description']]\n",
        "print(df_wine_merged_filtered.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pqGPy320FwF"
      },
      "source": [
        "Now, we will extract 7 vectors for every wine:\n",
        "\n",
        "- aroma vector (the aggregate of all the aroma descriptors in a wine)\n",
        "- nonaroma vectors (an aggregate vector for only aroma & non-aroma descriptors matching the core tastes below):\n",
        "    - sweetness\n",
        "    - acid\n",
        "    - salt\n",
        "    - piquant\n",
        "    - fat\n",
        "    - bitter\n",
        "    \n",
        " In our descriptor file, we have defined which normalized descriptors pertain to each nonaroma."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path2 = '/content/drive/My Drive/Final Project/wine_food_pairing/descriptor_mapping_tastes.csv'"
      ],
      "metadata": {
        "id": "egXNkmiOHk45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw9Ae_-J0FwF"
      },
      "outputs": [],
      "source": [
        "wine_reviews = list(df_wine_merged_filtered['description'])\n",
        "\n",
        "descriptor_mapping = pd.read_csv(file_path2, encoding='latin1').set_index('raw descriptor')\n",
        "\n",
        "core_tastes = ['aroma', 'weight', 'sweet', 'acid', 'salt', 'piquant', 'fat', 'bitter']\n",
        "descriptor_mappings = dict()\n",
        "for c in core_tastes:\n",
        "    if c=='aroma':\n",
        "        descriptor_mapping_filtered=descriptor_mapping.loc[descriptor_mapping['type']=='aroma']\n",
        "    else:\n",
        "        descriptor_mapping_filtered=descriptor_mapping.loc[descriptor_mapping['primary taste']==c]\n",
        "    descriptor_mappings[c] = descriptor_mapping_filtered\n",
        "\n",
        "\n",
        "def return_descriptor_from_mapping(descriptor_mapping, word, core_taste):\n",
        "    if word in list(descriptor_mapping.index):\n",
        "        descriptor_to_return = descriptor_mapping['combined'][word]\n",
        "        return descriptor_to_return\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "review_descriptors = []\n",
        "for review in wine_reviews:\n",
        "    taste_descriptors = []\n",
        "    normalized_review = normalize_text(review)\n",
        "    phrased_review = wine_trigram_model[normalized_review]\n",
        "#     print(phrased_review)\n",
        "\n",
        "    for c in core_tastes:\n",
        "        descriptors_only = [return_descriptor_from_mapping(descriptor_mappings[c], word, c) for word in phrased_review]\n",
        "        no_nones = [str(d).strip() for d in descriptors_only if d is not None]\n",
        "        descriptorized_review = ' '.join(no_nones)\n",
        "        taste_descriptors.append(descriptorized_review)\n",
        "    review_descriptors.append(taste_descriptors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOGm7ho_0FwF"
      },
      "source": [
        "Now we will take the list of descriptors for each wine and its aroma/nonaroma vectors and compute a TF-IDF weighted embedding for each. We will store the results in a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-2RKLx-0FwF"
      },
      "outputs": [],
      "source": [
        "taste_descriptors = []\n",
        "taste_vectors = []\n",
        "\n",
        "for n, taste in enumerate(core_tastes):\n",
        "    print(taste)\n",
        "    taste_words = [r[n] for r in review_descriptors]\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit(taste_words)\n",
        "    dict_of_tfidf_weightings = dict(zip(X.get_feature_names_out(), X.idf_))\n",
        "\n",
        "    wine_review_descriptors = []\n",
        "    wine_review_vectors = []\n",
        "\n",
        "    for d in taste_words:\n",
        "        descriptor_count = 0\n",
        "        weighted_review_terms = []\n",
        "        terms = d.split(' ')\n",
        "        for term in terms:\n",
        "            if term in dict_of_tfidf_weightings.keys():\n",
        "                tfidf_weighting = dict_of_tfidf_weightings[term]\n",
        "                try:\n",
        "                    word_vector = wine_word2vec_model.wv.get_vector(term).reshape(1, 300)\n",
        "                    weighted_word_vector = tfidf_weighting * word_vector\n",
        "                    weighted_review_terms.append(weighted_word_vector)\n",
        "                    descriptor_count += 1\n",
        "                except:\n",
        "                    continue\n",
        "            else:\n",
        "                continue\n",
        "        try:\n",
        "            review_vector = sum(weighted_review_terms)/len(weighted_review_terms)\n",
        "            review_vector = review_vector[0]\n",
        "        except:\n",
        "            review_vector = np.nan\n",
        "#         terms_and_vec = [terms, review_vector]\n",
        "        wine_review_vectors.append(review_vector)\n",
        "        wine_review_descriptors.append(terms)\n",
        "\n",
        "    taste_vectors.append(wine_review_vectors)\n",
        "    taste_descriptors.append(wine_review_descriptors)\n",
        "\n",
        "\n",
        "taste_vectors_t = list(map(list, zip(*taste_vectors)))\n",
        "taste_descriptors_t = list(map(list, zip(*taste_descriptors)))\n",
        "\n",
        "df_review_vecs = pd.DataFrame(taste_vectors_t, columns=core_tastes)\n",
        "\n",
        "columns_taste_descriptors = [a + '_descriptors' for a in core_tastes]\n",
        "df_review_descriptors = pd.DataFrame(taste_descriptors_t, columns=columns_taste_descriptors)\n",
        "\n",
        "df_wine_vecs = pd.concat([df_wine_merged_filtered, df_review_descriptors, df_review_vecs], axis=1)\n",
        "df_wine_vecs.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqu5mnQo0FwF"
      },
      "source": [
        "If we don't have a nonaroma embedding for one of the wines, we will simply take the average nonaroma embedding for all the wines in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVx98AMp0FwF"
      },
      "outputs": [],
      "source": [
        "# pull the average embedding for the wine attribute across all wines.\n",
        "avg_taste_vecs = dict()\n",
        "for t in core_tastes:\n",
        "    # look at the average embedding for a taste, across all wines that have descriptors for that taste\n",
        "    review_arrays = df_wine_vecs[t].dropna()\n",
        "    average_taste_vec = np.average(review_arrays)\n",
        "    avg_taste_vecs[t] = average_taste_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BUxc6Zq0FwF"
      },
      "source": [
        "Now, let's find the average embedding for each type of wine (aromas and all nonaromas). We have defined the different types of wines by grape variety and geography, keeping only those with a sufficiently large sample size.\n",
        "\n",
        "For each variety, we will pull (i) a 300-dimensional aroma vector, and (ii) 7 non-aroma scalars."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_wine_vecs.columns)"
      ],
      "metadata": {
        "id": "YXaR0jWXMSu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Reset NaN values in taste vectors to ensure clean data processing\n",
        "core_tastes = ['aroma', 'weight', 'sweet', 'acid', 'salt', 'piquant', 'fat', 'bitter']\n",
        "\n",
        "# Function to replace NaN values with average or fallback vectors\n",
        "def replace_nan_with_avg(df, core_tastes, avg_vecs):\n",
        "    for taste in core_tastes:\n",
        "        valid_vectors = [x for x in df[taste] if isinstance(x, np.ndarray)]\n",
        "        if valid_vectors:\n",
        "            avg_vecs[taste] = np.mean(valid_vectors, axis=0)  # Calculate average\n",
        "        else:\n",
        "            avg_vecs[taste] = np.zeros(300)  # Fallback to zeros if no valid vectors\n",
        "\n",
        "        df[taste] = df[taste].apply(lambda x: avg_vecs[taste] if not isinstance(x, np.ndarray) else x)\n",
        "    return df\n",
        "\n",
        "# Subset wine vectors for PCA\n",
        "def subset_wine_vectors(list_of_varieties, wine_attribute):\n",
        "    wine_variety_vectors = []\n",
        "    for v in list_of_varieties:\n",
        "        subset = df_wine_vecs[\n",
        "            (df_wine_vecs['variety'] == v[0]) & (df_wine_vecs['geo_normalized'] == v[1])\n",
        "        ]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        taste_vecs = subset[wine_attribute].tolist()\n",
        "        taste_vecs = [\n",
        "            avg_taste_vecs[wine_attribute] if not isinstance(x, np.ndarray) else x for x in taste_vecs\n",
        "        ]\n",
        "        average_variety_vec = np.mean(taste_vecs, axis=0)\n",
        "\n",
        "        descriptor_colname = wine_attribute + '_descriptors'\n",
        "        all_descriptors = [\n",
        "            descriptor for descriptors_list in subset[descriptor_colname]\n",
        "            for descriptor in descriptors_list\n",
        "        ]\n",
        "        word_freqs = Counter(all_descriptors)\n",
        "        most_common_words = word_freqs.most_common(50)\n",
        "        top_n_words = [(i[0], \"{:.2f}\".format(i[1] / len(taste_vecs))) for i in most_common_words]\n",
        "        wine_variety_vector = [v, average_variety_vec, top_n_words]\n",
        "\n",
        "        wine_variety_vectors.append(wine_variety_vector)\n",
        "\n",
        "    return wine_variety_vectors\n",
        "\n",
        "# PCA processing for wine varieties\n",
        "def pca_wine_variety(list_of_varieties, wine_attribute, pca=True):\n",
        "    wine_var_vectors = subset_wine_vectors(list_of_varieties, wine_attribute)\n",
        "\n",
        "    # Ensure valid data before applying PCA\n",
        "    wine_varieties = [w[0] for w in wine_var_vectors]\n",
        "    wine_var_vec = np.array([w[1] for w in wine_var_vectors])\n",
        "\n",
        "    if len(wine_var_vec) == 0 or len(wine_var_vec.shape) < 2:\n",
        "        print(f\"No valid data for {wine_attribute}. Skipping...\")\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    if pca:\n",
        "        pca_model = PCA(n_components=1)\n",
        "        wine_var_vec = pca_model.fit_transform(wine_var_vec)\n",
        "        wine_var_vec = pd.DataFrame(wine_var_vec, index=wine_varieties)\n",
        "    else:\n",
        "        wine_var_vec = pd.DataFrame(wine_var_vec, index=wine_varieties)\n",
        "\n",
        "    wine_descriptors = pd.DataFrame([w[2] for w in wine_var_vectors], index=wine_varieties)\n",
        "    return wine_var_vec, wine_descriptors\n",
        "\n",
        "# Initialize variables\n",
        "avg_taste_vecs = {}\n",
        "normalized_geos = list(set(zip(df_wine_vecs['variety'], df_wine_vecs['geo_normalized'])))\n",
        "\n",
        "# Replace NaN values with averages\n",
        "df_wine_vecs = replace_nan_with_avg(df_wine_vecs, core_tastes, avg_taste_vecs)\n",
        "\n",
        "# Generate taste vectors and descriptors\n",
        "taste_dataframes = []\n",
        "aroma_vec, aroma_descriptors = pca_wine_variety(normalized_geos, 'aroma', pca=False)\n",
        "taste_dataframes.append(aroma_vec)\n",
        "\n",
        "for taste in core_tastes[1:]:\n",
        "    print(f\"Processing taste: {taste}\")\n",
        "    pca_df, descriptors_df = pca_wine_variety(normalized_geos, taste, pca=True)\n",
        "    taste_dataframes.append(pca_df)\n",
        "\n",
        "# Combine taste dataframes\n",
        "all_taste_data = pd.concat(taste_dataframes, axis=1)\n",
        "\n",
        "# Rename columns to match core tastes\n",
        "if all_taste_data.shape[1] == len(core_tastes):\n",
        "    all_taste_data.columns = core_tastes\n",
        "else:\n",
        "    print(f\"Column mismatch: Expected {len(core_tastes)} but got {all_taste_data.shape[1]}.\")\n",
        "\n",
        "# Final output\n",
        "print(all_taste_data.head())"
      ],
      "metadata": {
        "id": "SoiSHAxzTF0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3ysQ8zE0FwF"
      },
      "outputs": [],
      "source": [
        "normalized_geos = list(set(zip(df_wine_vecs['variety'], df_wine_vecs['geo_normalized'])))\n",
        "\n",
        "def subset_wine_vectors(list_of_varieties, wine_attribute):\n",
        "    wine_variety_vectors = []\n",
        "    for v in list_of_varieties:\n",
        "\n",
        "        one_var_only = df_wine_vecs.loc[(df_wine_vecs['variety'] == v[0]) &\n",
        "                                                (df_wine_vecs['geo_normalized'] == v[1])]\n",
        "        if len(list(one_var_only.index)) < 1 or str(v[1][-1]) == '0':\n",
        "            continue\n",
        "        else:\n",
        "            taste_vecs = list(one_var_only[wine_attribute])\n",
        "            taste_vecs = [avg_taste_vecs[wine_attribute] if 'numpy' not in str(type(x)) else x for x in taste_vecs]\n",
        "            average_variety_vec = np.average(taste_vecs, axis=0)\n",
        "\n",
        "            descriptor_colname = wine_attribute + '_descriptors'\n",
        "            all_descriptors = [i[0] for i in list(one_var_only[descriptor_colname])]\n",
        "            word_freqs = Counter(all_descriptors)\n",
        "            most_common_words = word_freqs.most_common(50)\n",
        "            top_n_words = [(i[0], \"{:.2f}\".format(i[1]/len(taste_vecs))) for i in most_common_words]\n",
        "            top_n_words = [i for i in top_n_words if len(i[0])>2]\n",
        "            wine_variety_vector = [v, average_variety_vec, top_n_words]\n",
        "\n",
        "            wine_variety_vectors.append(wine_variety_vector)\n",
        "\n",
        "    return wine_variety_vectors\n",
        "\n",
        "\n",
        "def pca_wine_variety(list_of_varieties, wine_attribute, pca=True):\n",
        "    wine_var_vectors = subset_wine_vectors(normalized_geos, wine_attribute)\n",
        "\n",
        "    wine_varieties = [str(w[0]).replace('(', '').replace(')', '').replace(\"'\", '').replace('\"', '') for w in wine_var_vectors]\n",
        "    wine_var_vec = [w[1] for w in wine_var_vectors]\n",
        "    if pca:\n",
        "        pca = PCA(1)\n",
        "        wine_var_vec = pca.fit_transform(wine_var_vec)\n",
        "        wine_var_vec = pd.DataFrame(wine_var_vec, index=wine_varieties)\n",
        "    else:\n",
        "        wine_var_vec = pd.Series(wine_var_vec, index=wine_varieties)\n",
        "    wine_var_vec.sort_index(inplace=True)\n",
        "\n",
        "    wine_descriptors = pd.DataFrame([w[2] for w in wine_var_vectors], index=wine_varieties)\n",
        "    wine_descriptors = pd.melt(wine_descriptors.reset_index(), id_vars='index')\n",
        "    wine_descriptors.sort_index(inplace=True)\n",
        "\n",
        "    return wine_var_vec, wine_descriptors\n",
        "\n",
        "taste_dataframes = []\n",
        "# generate the dataframe of aromas vectors as output,\n",
        "aroma_vec, aroma_descriptors = pca_wine_variety(normalized_geos, 'aroma', pca=False)\n",
        "taste_dataframes.append(aroma_vec)\n",
        "\n",
        "# generate the dataframes of nonaroma scalars\n",
        "for tw in core_tastes[1:]:\n",
        "    pca_w_dataframe, nonaroma_descriptors = pca_wine_variety(normalized_geos, tw, pca=True)\n",
        "    taste_dataframes.append(pca_w_dataframe)\n",
        "\n",
        "# combine all the dataframes created above into one\n",
        "all_nonaromas = pd.concat(taste_dataframes, axis=1)\n",
        "all_nonaromas.columns = core_tastes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eULxg8i0FwF"
      },
      "outputs": [],
      "source": [
        "# save the 50 top descriptors for each wine variety as a CSV file. We will us this later to dig deeper into our proposed wine recommendations.\n",
        "\n",
        "aroma_descriptors_copy = aroma_descriptors.copy()\n",
        "aroma_descriptors_copy.set_index('index', inplace=True)\n",
        "aroma_descriptors_copy.dropna(inplace=True)\n",
        "\n",
        "aroma_descriptors_copy = pd.DataFrame(aroma_descriptors_copy['value'].tolist(), index=aroma_descriptors_copy.index)\n",
        "aroma_descriptors_copy.columns = ['descriptors', 'relative_frequency']\n",
        "aroma_descriptors_copy.to_csv('wine_variety_descriptors.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aroma_descriptors_copy.head()"
      ],
      "metadata": {
        "id": "bLgo6l6wWp7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4jjPIgx0FwF"
      },
      "source": [
        "At the moment, it's hard to interpret the nonaroma scalars. To allow for greater interpretability, we will normalize the nonaroma scalars between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_nonaromas['bitter'].unique()"
      ],
      "metadata": {
        "id": "JWbNQXVcXHXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(df, cols_to_normalize):\n",
        "    for feature_name in cols_to_normalize:\n",
        "        print(f\"Normalizing: {feature_name}\")\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()\n",
        "\n",
        "        # Handle constant columns to avoid division by zero\n",
        "        if max_value == min_value:\n",
        "            print(f\"Column '{feature_name}' has constant values. Assigning 0 to all entries.\")\n",
        "            df[feature_name] = 0  # Assign 0 to all rows in constant columns\n",
        "        else:\n",
        "            # Apply normalization\n",
        "            df[feature_name] = df[feature_name].apply(lambda x: (x - min_value) / (max_value - min_value))\n",
        "    return df\n",
        "\n",
        "# Normalize non-aroma columns\n",
        "all_nonaromas_normalized = normalize(all_nonaromas, cols_to_normalize=core_tastes[1:])\n",
        "\n",
        "# Save the normalized data to a CSV file\n",
        "output_file = 'wine_aromas_nonaromas.csv'\n",
        "all_nonaromas_normalized.to_csv(output_file, index=False)\n",
        "print(f\"Normalized data saved to {output_file}\")"
      ],
      "metadata": {
        "id": "bCQro3tNVDI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubDnH0SU0FwG"
      },
      "source": [
        "### 3. Preparing our Food Dataset\n",
        "\n",
        "Now that we have our wine aroma vectors and the nonaroma scalars, we can turn our attention to food.\n",
        "\n",
        "We will want to generate nonaroma vectors for any type of food that we want a wine pairing with. For food, we don't have the luxury of being able to define nonaroma vs. aroma descriptors, so the approach we take will be slightly different:\n",
        "\n",
        "The aroma vector will be the full food embedding.\n",
        "\n",
        "We will define an embedding for each of our core nonaromas (sweet, acid, salt, piquant, fat and bitter), and the weight/body of the food. We will define the maximum distance between each of the nonaroma embeddings and a range of commonly appearing foods. The foods that least and most resemble each nonaroma will eventually allow us to create a normalized scale between 0 (very dissimilar) and 1 (very similar) to say how much a food reflects each nonaroma.\n",
        "\n",
        "First, let's load this list of common foods."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path3 = '/content/drive/My Drive/Final Project/wine_food_pairing/list_of_foods.csv'"
      ],
      "metadata": {
        "id": "bM0OdAjpXh_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfeHrkeC0FwG"
      },
      "outputs": [],
      "source": [
        "foods = pd.read_csv(file_path3)\n",
        "foods_list = list(foods['Food'])\n",
        "foods_list_normalized = [normalize_text(f) for f in foods_list]\n",
        "foods_list_preprocessed = [food_trigram_model[f][0] for f in foods_list_normalized]\n",
        "foods_list_preprocessed = list(set(foods_list_preprocessed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg_YmMyM0FwG"
      },
      "source": [
        "Load the word embedding for each food in the list of sample foods, and save to a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6df4xSA0FwG"
      },
      "outputs": [],
      "source": [
        "foods_vecs = dict()\n",
        "\n",
        "word_vectors = wine_word2vec_model.wv\n",
        "for f in foods_list_preprocessed:\n",
        "    try:\n",
        "        food_vec = word_vectors[f]\n",
        "        foods_vecs[f] = food_vec\n",
        "    except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROb5mydF0FwG"
      },
      "source": [
        "Now, we can define the nonaroma embeddings + the weight embedding as the average of foods that represent each nonaroma characteristic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdDR59tB0FwG"
      },
      "outputs": [],
      "source": [
        "from scipy import spatial\n",
        "\n",
        "core_tastes_revised = {'weight': ['heavy', 'cassoulet', 'cassoulet', 'full_bodied', 'thick', 'milk', 'fat', 'mincemeat', 'steak', 'bold', 'pizza', 'pasta', 'creamy', 'bread'],\n",
        "                       'sweet': ['sweet', 'sugar', 'cake', 'mango', 'stevia'],\n",
        "                       'acid': ['acid', 'sour', 'vinegar', 'yoghurt', 'cevich', 'cevich'],\n",
        "                       'salt': ['salty', 'salty', 'parmesan', 'oyster', 'pizza', 'bacon', 'cured_meat', 'sausage', 'potato_chip'],\n",
        "                       'piquant': ['spicy'],\n",
        "                       'fat': ['fat', 'fried', 'creamy', 'cassoulet', 'foie_gras', 'buttery', 'cake', 'foie_gras', 'sausage', 'brie', 'carbonara'],\n",
        "                       'bitter': ['bitter', 'kale']\n",
        "                      }\n",
        "\n",
        "average_taste_vecs = dict()\n",
        "core_tastes_distances = dict()\n",
        "for taste, keywords in core_tastes_revised.items():\n",
        "\n",
        "    all_keyword_vecs = []\n",
        "    for keyword in keywords:\n",
        "        c_vec = word_vectors[keyword]\n",
        "        all_keyword_vecs.append(c_vec)\n",
        "\n",
        "    avg_taste_vec = np.average(all_keyword_vecs, axis=0)\n",
        "    average_taste_vecs[taste] = avg_taste_vec\n",
        "\n",
        "    taste_distances = dict()\n",
        "    for k, v in foods_vecs.items():\n",
        "        similarity = 1- spatial.distance.cosine(avg_taste_vec, v)\n",
        "        taste_distances[k] = similarity\n",
        "\n",
        "    core_tastes_distances[taste] = taste_distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw5tSkk70FwG"
      },
      "source": [
        "We can now find out which foods most and least resemble each nonaroma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "qfls67gB0FwG"
      },
      "outputs": [],
      "source": [
        "food_nonaroma_infos = dict()\n",
        "# for each core taste, identify the food item that is farthest and closest. We will need this to create a normalized scale between 0 and 1\n",
        "for key, value in core_tastes_revised.items():\n",
        "    dict_taste = dict()\n",
        "    farthest = min(core_tastes_distances[key], key=core_tastes_distances[key].get)\n",
        "    farthest_distance = core_tastes_distances[key][farthest]\n",
        "    closest = max(core_tastes_distances[key], key=core_tastes_distances[key].get)\n",
        "    closest_distance = core_tastes_distances[key][closest]\n",
        "    print(key, farthest, closest)\n",
        "    dict_taste['farthest'] = farthest_distance\n",
        "    dict_taste['closest'] = closest_distance\n",
        "    dict_taste['average_vec'] = average_taste_vecs[key]\n",
        "    food_nonaroma_infos[key] = dict_taste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPTsS-6G0FwG"
      },
      "source": [
        "Now, let's save the average embedding for each nonaroma, as well as the minimum and maximum distance to each nonaroma embedding - we will use these to scale the nonaroma scalars that we obtain for any foods we try to pair wine with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FrFgF-50FwG"
      },
      "outputs": [],
      "source": [
        "df_food_nonaroma_infos = pd.DataFrame(food_nonaroma_infos).T\n",
        "df_food_nonaroma_infos.to_csv('average_nonaroma_vectors.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw8JH5MO0FwG"
      },
      "source": [
        "We have all the pieces we need to build our wine recommendations. We will continue with this in a separate notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check current working directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "# List all files in the current directory\n",
        "print(\"Files in the current directory:\")\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "id": "Gkr5dv1UYK0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check files in your Google Drive folder\n",
        "print(\"Files in the Drive folder:\")\n",
        "print(os.listdir('/content/drive/My Drive/Final Project/wine_food_pairing'))"
      ],
      "metadata": {
        "id": "ZsgMZPE-YVPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define source and target directories\n",
        "source_dir = '/content'\n",
        "target_dir = '/content/drive/My Drive/Final Project/wine_food_pairing'\n",
        "\n",
        "# Ensure the target directory exists\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# List all files and directories in the source directory\n",
        "files_to_move = [f for f in os.listdir(source_dir) if f != 'drive']\n",
        "\n",
        "# Move files to the target directory\n",
        "for file_name in files_to_move:\n",
        "    source_path = os.path.join(source_dir, file_name)\n",
        "    target_path = os.path.join(target_dir, file_name)\n",
        "\n",
        "    try:\n",
        "        # Move only if it's a file or directory other than 'drive'\n",
        "        if os.path.isfile(source_path) or os.path.isdir(source_path):\n",
        "            shutil.move(source_path, target_path)\n",
        "            print(f\"Moved: {file_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error moving {file_name}: {e}\")\n",
        "\n",
        "print(\"All files have been moved.\")"
      ],
      "metadata": {
        "id": "TqLPaT61ZrPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}